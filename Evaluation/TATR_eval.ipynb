{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2AaTjoMuO-CH"
      },
      "source": [
        "# FUNÇÃO MAIN PARA RODAR O CODIGO EM LOTE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kafdzJ49ZbAo",
        "outputId": "04a60f41-6d90-4a6f-a0e9-9fff65d51bfd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "#montando o caminho para leitura dos arquivos (certificados, imagens, planilhas, etc)\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U_oN94h5Z242"
      },
      "outputs": [],
      "source": [
        "from IPython.display import clear_output\n",
        "!pip install -q transformers\n",
        "!pip install -q easyocr\n",
        "!pip install pymupdf\n",
        "!pip install pdf2image\n",
        "!apt-get install poppler-utils\n",
        "clear_output()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6m-9Ge_OtCcK"
      },
      "outputs": [],
      "source": [
        "#Bibliotecas\n",
        "from datetime import datetime\n",
        "import pytz\n",
        "from PIL import Image\n",
        "from PIL import ImageDraw\n",
        "from huggingface_hub import hf_hub_download\n",
        "import fitz\n",
        "import os\n",
        "import pandas as pd\n",
        "import copy\n",
        "#funcao para converter PDF para png\n",
        "from pdf2image import convert_from_path\n",
        "from torchvision import transforms\n",
        "import torch\n",
        "#Modelo de deteccao de tabela\n",
        "from transformers import AutoModelForObjectDetection\n",
        "#modelo de estrutura\n",
        "from transformers import TableTransformerForObjectDetection\n",
        "import numpy as np\n",
        "import csv\n",
        "#import easyocr\n",
        "from tqdm.auto import tqdm\n",
        "import cv2\n",
        "from bs4 import BeautifulSoup as bs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-I1SwXGHPEg1"
      },
      "source": [
        "Variáveis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QLvqOK87PB8u"
      },
      "outputs": [],
      "source": [
        "#caminho dos certificados para analise\n",
        "CERT_PATH = \"/content/drive/MyDrive/DataSets/Certificados/In/\"\n",
        "\n",
        "#caminho de saida para geração das anotações das tabelas\n",
        "OUT_PATH = \"/content/drive/MyDrive/DataSets/Certificados/Out/Test/\"\n",
        "\n",
        "#diretorio dos arquivos do GT - Ground Truth (REFERENCIA para comparacao das tabelas)\n",
        "GT_PATH = \"/content/drive/MyDrive/DataSets/Certificados/Out/GT/\"\n",
        "\n",
        "#diretorio de escrita de arquivos\n",
        "DIROUT_PUBTABLES = \"/content/drive/MyDrive/DataSets/Certificados/Out/PubTables/\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jg9qkYiVPKBX"
      },
      "source": [
        "Funções de Préprocessamento"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UuIi27gvNU63"
      },
      "outputs": [],
      "source": [
        "#funcao para varrer os arquivos PDF dos laboratórios nas pastas e retorna um dataframe\n",
        "#! o método está bem lento (deve verificar o motivo posteriormente)\n",
        "def InfoPDF(pathPDF):\n",
        "\n",
        "  lenPages = 0\n",
        "  doc = fitz.open(pathPDF)\n",
        "\n",
        "  lenPages = len(doc)\n",
        "  for pagina in doc:\n",
        "    isText = bool(pagina.get_text())\n",
        "    break\n",
        "\n",
        "  typeArq = [\"TEXT\" if isText else \"IMAGE\"]\n",
        "\n",
        "  return typeArq, lenPages\n",
        "\n",
        "def listFiles_OLD(CERT_PATH):\n",
        "\n",
        "  dfArq = pd.DataFrame()\n",
        "  dirs = [nome for nome in os.listdir(CERT_PATH) if os.path.isdir(os.path.join(CERT_PATH, nome))]\n",
        "\n",
        "  i = 0\n",
        "  for dir in dirs:\n",
        "\n",
        "    #coletando dados do diretorio (id, laboratorio)\n",
        "    lstDir = dir.split(\"_\")\n",
        "\n",
        "    if(len(lstDir)==3):\n",
        "\n",
        "      for file in os.listdir(os.path.join(CERT_PATH, dir)):\n",
        "\n",
        "        #é arquivo PDF\n",
        "        if file.lower().endswith(\".pdf\"):\n",
        "\n",
        "          pathFile = CERT_PATH + dir + \"/\" + file\n",
        "          dfArq.at[i,\"LAB\"] = lstDir[2]\n",
        "          dfArq.at[i,'PATH'] = pathFile\n",
        "\n",
        "          typeArq, qtdPages = InfoPDF(pathFile)\n",
        "          dfArq.at[i,'TYPE'] = typeArq\n",
        "          dfArq.at[i,'QTDPAGES'] = qtdPages\n",
        "\n",
        "          i = i + 1\n",
        "\n",
        "  return dfArq\n",
        "\n",
        "def listFiles(CERT_PATH, LAB_PATH):\n",
        "\n",
        "  dfArq = pd.DataFrame()\n",
        "\n",
        "  if LAB_PATH is None:\n",
        "    dirs = [nome for nome in os.listdir(CERT_PATH) if os.path.isdir(os.path.join(CERT_PATH, nome))]\n",
        "  else:\n",
        "    dirs = [LAB_PATH]\n",
        "\n",
        "  i = 0\n",
        "  for dir in dirs:\n",
        "\n",
        "    #coletando dados do diretorio (id, laboratorio)\n",
        "    lstDir = dir.split(\"_\")\n",
        "    print(\"lstDir \", lstDir);\n",
        "\n",
        "    if(len(lstDir)==3):\n",
        "\n",
        "      for file in os.listdir(os.path.join(CERT_PATH, dir)):\n",
        "\n",
        "        #é arquivo PDF\n",
        "        if file.lower().endswith(\".pdf\"):\n",
        "\n",
        "          pathFile = CERT_PATH + dir + \"/\" + file\n",
        "          print(\"pathFile \", pathFile);\n",
        "          dfArq.at[i,\"LAB\"] = lstDir[2]\n",
        "          dfArq.at[i,'PATH'] = pathFile\n",
        "\n",
        "          typeArq, qtdPages = InfoPDF(pathFile)\n",
        "          dfArq.at[i,'TYPE'] = typeArq\n",
        "          dfArq.at[i,'QTDPAGES'] = qtdPages\n",
        "\n",
        "          i = i + 1\n",
        "\n",
        "  return dfArq\n",
        "\n",
        "#dfArq = listFiles(CERT_PATH)\n",
        "\n",
        "def deleteFiles2(dirpath):\n",
        "  # Obtém a lista de arquivos no diretório\n",
        "  files = os.listdir(dirpath)\n",
        "\n",
        "  # Itera sobre os arquivos e os remove\n",
        "  for file in files:\n",
        "    filepath = os.path.join(dirpath, file)\n",
        "    if os.path.isfile(filepath):\n",
        "      os.remove(filepath)\n",
        "\n",
        "def is_image_by_extension(file_path):\n",
        "  image_extensions = ['png', 'jpg', 'jpeg', 'gif', 'bmp', 'tiff', 'webp']  # Adicione outras extensões se necessário\n",
        "  file_extension = file_path.lower().split('.')[-1]\n",
        "  return file_extension in image_extensions\n",
        "\n",
        "def is_image(file_path):\n",
        "    try:\n",
        "        # Tenta abrir o arquivo como uma imagem\n",
        "        Image(file_path)\n",
        "        return True\n",
        "    except IOError:\n",
        "        # Se não for possível abrir como uma imagem, retorna False\n",
        "        return False\n",
        "\n",
        "def pdf_page_to_png(pdf_path, page_number, output_path):\n",
        "  # Convertendo a página do PDF para uma lista de imagens\n",
        "  images = convert_from_path(pdf_path, first_page=page_number, last_page=page_number)\n",
        "\n",
        "  # Salvando a imagem como PNG\n",
        "  images[0].save(output_path, 'PNG')\n",
        "\n",
        "class MaxResize(object):\n",
        "  def __init__(self, max_size=800):\n",
        "      self.max_size = max_size\n",
        "\n",
        "  def __call__(self, image):\n",
        "      width, height = image.size\n",
        "      current_max_size = max(width, height)\n",
        "      scale = self.max_size / current_max_size\n",
        "      resized_image = image.resize((int(round(scale*width)), int(round(scale*height))))\n",
        "\n",
        "      return resized_image\n",
        "\n",
        "def get_cell_coordinates_by_row(table_data):\n",
        "  # Extract rows and columns\n",
        "  rows = [entry for entry in table_data if entry['label'] == 'table row']\n",
        "  columns = [entry for entry in table_data if entry['label'] == 'table column']\n",
        "\n",
        "  # Sort rows and columns by their Y and X coordinates, respectively\n",
        "  rows.sort(key=lambda x: x['bbox'][1])\n",
        "  columns.sort(key=lambda x: x['bbox'][0])\n",
        "\n",
        "  # Function to find cell coordinates\n",
        "  def find_cell_coordinates(row, column):\n",
        "      cell_bbox = [column['bbox'][0], row['bbox'][1], column['bbox'][2], row['bbox'][3]]\n",
        "      return cell_bbox\n",
        "\n",
        "  # Generate cell coordinates and count cells in each row\n",
        "  cell_coordinates = []\n",
        "\n",
        "  for row in rows:\n",
        "      row_cells = []\n",
        "      for column in columns:\n",
        "          cell_bbox = find_cell_coordinates(row, column)\n",
        "          row_cells.append({'column': column['bbox'], 'cell': cell_bbox})\n",
        "\n",
        "      # Sort cells in the row by X coordinate\n",
        "      row_cells.sort(key=lambda x: x['column'][0])\n",
        "\n",
        "      # Append row information to cell_coordinates\n",
        "      cell_coordinates.append({'row': row['bbox'], 'cells': row_cells, 'cell_count': len(row_cells)})\n",
        "\n",
        "  # Sort rows from top to bottom\n",
        "  cell_coordinates.sort(key=lambda x: x['row'][1])\n",
        "\n",
        "  return cell_coordinates\n",
        "\n",
        "def aumentar_qualidade_e_contraste(imagem_path, fator_contraste, fator_brilho):\n",
        "  # Carregar a imagem\n",
        "  imagem = cv2.imread(imagem_path)\n",
        "\n",
        "  # Converter a imagem para o espaço de cores LAB (Luminância, Azul, Vermelho)\n",
        "  lab = cv2.cvtColor(imagem, cv2.COLOR_BGR2LAB)\n",
        "\n",
        "  # Separar os canais L, A, B\n",
        "  l, a, b = cv2.split(lab)\n",
        "\n",
        "  # Aplicar o aumento de contraste na imagem L (luminância)\n",
        "  l = cv2.add(l, fator_brilho)\n",
        "  l = cv2.multiply(l, fator_contraste)\n",
        "\n",
        "  # Mesclar novamente os canais LAB\n",
        "  lab = cv2.merge((l, a, b))\n",
        "\n",
        "  # Converter a imagem de volta para o espaço de cores BGR\n",
        "  imagem_contraste = cv2.cvtColor(lab, cv2.COLOR_LAB2BGR)\n",
        "\n",
        "  return imagem_contraste"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i6gv06XP4-o3"
      },
      "outputs": [],
      "source": [
        "#funcoes de pré-processamento dos modelos\n",
        "\n",
        "# for output bounding box post-processing\n",
        "def box_cxcywh_to_xyxy(x):\n",
        "    x_c, y_c, w, h = x.unbind(-1)\n",
        "    b = [(x_c - 0.5 * w), (y_c - 0.5 * h), (x_c + 0.5 * w), (y_c + 0.5 * h)]\n",
        "    return torch.stack(b, dim=1)\n",
        "\n",
        "\n",
        "def rescale_bboxes(out_bbox, size):\n",
        "    img_w, img_h = size\n",
        "    b = box_cxcywh_to_xyxy(out_bbox)\n",
        "    b = b * torch.tensor([img_w, img_h, img_w, img_h], dtype=torch.float32)\n",
        "    return b\n",
        "\n",
        "def outputs_to_objects(outputs, img_size, id2label):\n",
        "    m = outputs.logits.softmax(-1).max(-1)\n",
        "    pred_labels = list(m.indices.detach().cpu().numpy())[0]\n",
        "    pred_scores = list(m.values.detach().cpu().numpy())[0]\n",
        "    pred_bboxes = outputs['pred_boxes'].detach().cpu()[0]\n",
        "    pred_bboxes = [elem.tolist() for elem in rescale_bboxes(pred_bboxes, img_size)]\n",
        "\n",
        "    objects = []\n",
        "    for label, score, bbox in zip(pred_labels, pred_scores, pred_bboxes):\n",
        "        class_label = id2label[int(label)]\n",
        "        if not class_label == 'no object':\n",
        "            objects.append({'label': class_label, 'score': float(score),\n",
        "                            'bbox': [float(elem) for elem in bbox]})\n",
        "\n",
        "    return objects\n",
        "\n",
        "def objects_to_crops(img, tokens, objects, class_thresholds, padding=10):\n",
        "    \"\"\"\n",
        "    Process the bounding boxes produced by the table detection model into\n",
        "    cropped table images and cropped tokens.\n",
        "    \"\"\"\n",
        "\n",
        "    table_crops = []\n",
        "    for obj in objects:\n",
        "        if obj['score'] < class_thresholds[obj['label']]:\n",
        "            continue\n",
        "\n",
        "        cropped_table = {}\n",
        "\n",
        "        bbox = obj['bbox']\n",
        "        bbox = [bbox[0]-padding, bbox[1]-padding, bbox[2]+padding, bbox[3]+padding]\n",
        "\n",
        "        cropped_img = img.crop(bbox)\n",
        "\n",
        "        table_tokens = [token for token in tokens if iob(token['bbox'], bbox) >= 0.5]\n",
        "        for token in table_tokens:\n",
        "            token['bbox'] = [token['bbox'][0]-bbox[0],\n",
        "                             token['bbox'][1]-bbox[1],\n",
        "                             token['bbox'][2]-bbox[0],\n",
        "                             token['bbox'][3]-bbox[1]]\n",
        "\n",
        "        # If table is predicted to be rotated, rotate cropped image and tokens/words:\n",
        "        if obj['label'] == 'table rotated':\n",
        "            cropped_img = cropped_img.rotate(270, expand=True)\n",
        "            for token in table_tokens:\n",
        "                bbox = token['bbox']\n",
        "                bbox = [cropped_img.size[0]-bbox[3]-1,\n",
        "                        bbox[0],\n",
        "                        cropped_img.size[0]-bbox[1]-1,\n",
        "                        bbox[2]]\n",
        "                token['bbox'] = bbox\n",
        "\n",
        "        cropped_table['image'] = cropped_img\n",
        "        cropped_table['tokens'] = table_tokens\n",
        "\n",
        "        table_crops.append(cropped_table)\n",
        "\n",
        "    return table_crops"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FK2aheBjQiHz"
      },
      "outputs": [],
      "source": [
        "#FUNÇÕES DE MANIPULACAO DE IMAGENS E ARQUIVOS\n",
        "\n",
        "#ler dados da celula\n",
        "def apply_ocr(cell_coordinates):\n",
        "    # let's OCR row by row\n",
        "    data = dict()\n",
        "    max_num_columns = 0\n",
        "    for idx, row in enumerate(tqdm(cell_coordinates)):\n",
        "      row_text = []\n",
        "      for cell in row[\"cells\"]:\n",
        "        # crop cell out of image\n",
        "        cell_image = np.array(cropped_table.crop(cell[\"cell\"]))\n",
        "        # apply OCR\n",
        "        result = reader.readtext(np.array(cell_image))\n",
        "        if len(result) > 0:\n",
        "          # print([x[1] for x in list(result)])\n",
        "          text = \" \".join([x[1] for x in result])\n",
        "          row_text.append(text)\n",
        "\n",
        "      if len(row_text) > max_num_columns:\n",
        "          max_num_columns = len(row_text)\n",
        "\n",
        "      data[idx] = row_text\n",
        "\n",
        "    #print(\"Max number of columns:\", max_num_columns)\n",
        "\n",
        "    # pad rows which don't have max_num_columns elements\n",
        "    # to make sure all rows have the same number of columns\n",
        "    for row, row_data in data.copy().items():\n",
        "        if len(row_data) != max_num_columns:\n",
        "          row_data = row_data + [\"\" for _ in range(max_num_columns - len(row_data))]\n",
        "        data[row] = row_data\n",
        "\n",
        "    return data\n",
        "\n",
        "#similaridade de strings conhecido como \"Distância de Levenshtein\"\n",
        "def calcPercSimStrings(str1, str2):\n",
        "\n",
        "  #retirando quebra de linhas da string\n",
        "  str1 = str1.replace(\"\\n\", \" \")\n",
        "  str2 = str2.replace(\"\\n\", \" \")\n",
        "\n",
        "  tamanho_str1 = len(str1)\n",
        "  tamanho_str2 = len(str2)\n",
        "\n",
        "  matriz = [[0] * (tamanho_str2 + 1) for _ in range(tamanho_str1 + 1)]\n",
        "\n",
        "  for i in range(tamanho_str1 + 1):\n",
        "    matriz[i][0] = i\n",
        "\n",
        "  for j in range(tamanho_str2 + 1):\n",
        "    matriz[0][j] = j\n",
        "\n",
        "  for i in range(1, tamanho_str1 + 1):\n",
        "    for j in range(1, tamanho_str2 + 1):\n",
        "        if str1[i - 1] == str2[j - 1]:\n",
        "            custo_substituicao = 0\n",
        "        else:\n",
        "            custo_substituicao = 1\n",
        "        matriz[i][j] = min(matriz[i - 1][j] + 1,       # Deletar\n",
        "                            matriz[i][j - 1] + 1,       # Inserir\n",
        "                              matriz[i - 1][j - 1] + custo_substituicao)  # Substituir\n",
        "\n",
        "  distancia = matriz[tamanho_str1][tamanho_str2]\n",
        "  maximo_tamanho = max(tamanho_str1, tamanho_str2)\n",
        "\n",
        "  similaridade = 0\n",
        "  if maximo_tamanho > 0:\n",
        "    similaridade = (maximo_tamanho - distancia) / maximo_tamanho\n",
        "  #print (\" similaridade entre {0} e {1}: {2}\".format(str1, str2, similaridade * 100))\n",
        "  return similaridade * 100\n",
        "\n",
        "#funcao que compara o valor de duas listas e calcula a media do percentual de similaridade entre eles\n",
        "#(para calcular o valor do bbox das tabelas e células das tabelas)\n",
        "\n",
        "def calcPercSimValueLists(lista1, lista2):\n",
        "  if len(lista1) != len(lista2):\n",
        "      print(\"calcPercSimValueLists, listas de tamanhos diferentes, lista1=\",lista1,\"/ lista2 = \",lista2)\n",
        "      raise ValueError(\"As listas devem ter o mesmo comprimento.\")\n",
        "\n",
        "  percSim = [ (1 / (1 + (abs(num1 - num2)))) * 100 for num1, num2 in zip(lista1, lista2)]\n",
        "\n",
        "\n",
        "  return sum(percSim) / len (percSim)\n",
        "\n",
        "#(para calcular o percentual de similaridade entre dois números\n",
        "def calcPercSimValueNums(num1, num2):\n",
        "\n",
        "  percSim = (1 / (1 + (abs(num1 - num2)))) * 100\n",
        "  #print (\" similaridade entre os numeros {0} e {1}: {2}\".format(num1, num2, percSim))\n",
        "  return percSim\n",
        "\n",
        "#coletar os arquivos de acordo com premissas (prefixo e sufixo)\n",
        "def getFilesByPrefix(path, prefix, sufix):\n",
        "  lstFiles = []\n",
        "  for fileName in os.listdir(path):\n",
        "      if prefix in fileName and fileName.endswith(sufix):\n",
        "          lstFiles.append(fileName)\n",
        "  return lstFiles\n",
        "\n",
        "#coletar no arquivo do GT dados das tabelas de uma determinada pagina\n",
        "def getListFilesGTInfo(curfile, page, path):\n",
        "\n",
        "  prefix = curfile + \"|\" + str(page)\n",
        "  sufix = \"_INFO.info\"\n",
        "  lstTables = getFilesByPrefix (path, prefix, sufix)\n",
        "\n",
        "  return lstTables\n",
        "\n",
        "def getGTInfo(tableID, curfile, page, path):\n",
        "\n",
        "  prefix = tableID + \"|\" + curfile + \"|\" + str(page)\n",
        "  sufix = \"_INFO.info\"\n",
        "  lstTables = getFilesByPrefix (path, prefix, sufix)\n",
        "\n",
        "  return lstTables\n",
        "\n",
        "#coletar as informacoes da tabela do arquivo _INFO e retornar para uma lista\n",
        "def getListTablesInfo(path, listFiles):\n",
        "\n",
        "  listTablesInfo = []\n",
        "  for fileName in listFiles:\n",
        "    with open(path + fileName, 'r') as file:\n",
        "      conteudo = file.read()\n",
        "      listTablesInfo.append(eval(conteudo))\n",
        "\n",
        "  return listTablesInfo\n",
        "\n",
        "# verificar se a estrutura dos dois dicionários INFO são similares\n",
        "def checkDimensionINFO(dicTableGT, dicTable):\n",
        "\n",
        "  msgErro = \"0 - SUCESSO\"\n",
        "  isIdentical = True\n",
        "\n",
        "  #se o tamanho das chaves dos dicionários são diferentes\n",
        "  if(dicTableGT.keys() != dicTable.keys()):\n",
        "    print(\"Dicionários não possuem o mesmo indice\")\n",
        "    msgErro = \"1 - Dicionários não possuem o mesmo indice\"\n",
        "    isIdentical = False\n",
        "\n",
        "  #se não tiver a mesma dimensao já descarta\n",
        "  if dicTableGT[\"DIMENSION\"] != dicTable[\"DIMENSION\"]:\n",
        "    msgErro = \"2 - Dicionários não possuem a mesma dimensão\"\n",
        "    isIdentical = False\n",
        "\n",
        "  #se o tamanho das colunas HEAD e FIRST_LINE não batem\n",
        "  if(len(dicTableGT[\"HEAD\"]) != len(dicTable[\"HEAD\"])):\n",
        "    print(\"Dicionários não possuem o mesmo tamanho da chave HEAD\")\n",
        "    msgErro = \"3 - Dicionários não possuem o mesmo tamanho da chave HEAD\"\n",
        "    isIdentical = False\n",
        "\n",
        "  if(len(dicTableGT[\"FIRST_LINE\"]) != len(dicTable[\"FIRST_LINE\"])):\n",
        "    msgErro = \"4 - Dicionários não possuem o mesmo tamanho da chave FIRST_LINE\"\n",
        "    isIdentical = False\n",
        "\n",
        "  #return msgErro, isSimilar\n",
        "  return isIdentical\n",
        "\n",
        "#calcular similaridade da string das células dos dicionários INFO de mesma dimensão\n",
        "#(para determinar se dois dicionarios INFO sao similares)\n",
        "def getPercSimTablesINFO(dicTableGT, dicTable , percTolerancia):\n",
        "\n",
        "  i = 0\n",
        "  for textTableGT in dicTableGT[\"HEAD\"]:\n",
        "    textTable = dicTable[\"HEAD\"][i]\n",
        "    if (calcPercSimStrings(textTableGT, textTable) < percTolerancia):\n",
        "      print(\"Tolerancia entre string \", textTableGT, \"e \", textTable,  \" menor que \", percTolerancia)\n",
        "      return False\n",
        "    i+=1\n",
        "\n",
        "  i = 0\n",
        "  for textTableGT in dicTableGT[\"FIRST_LINE\"]:\n",
        "    textTable = dicTable[\"FIRST_LINE\"][i]\n",
        "    if (calcPercSimStrings(textTableGT, textTable) < percTolerancia):\n",
        "      print(\"Tolerancia entre string \", textTableGT, \"e \", textTable,  \" menor que \", percTolerancia)\n",
        "      return False\n",
        "    i+=1\n",
        "\n",
        "  return True\n",
        "\n",
        "\n",
        "#verifica se a dimensão dos dicionários INFO possuem tamanhos parecidos (maximo 1 de diferença)\n",
        "def isAlmostSimilarINFO(dicTableGT, dicTable):\n",
        "\n",
        "  #devem possuir a mesma quantidade de linhas e quantidade semelhante de colunas (maximo no modulo 1)\n",
        "\n",
        "  #colunas\n",
        "  qtdColGT = len(dicTableGT[\"HEAD\"])\n",
        "  qtdColTab = len(dicTable[\"HEAD\"])\n",
        "\n",
        "  #linhas\n",
        "  qtdLinhasGT = dicTableGT[\"DIMENSION\"].split(\"X\")[0]\n",
        "  qtdLinhas = dicTable[\"DIMENSION\"].split(\"X\")[0]\n",
        "\n",
        "  if abs(qtdColGT-qtdColTab) <=1 and qtdLinhasGT == qtdLinhas:\n",
        "    return True\n",
        "\n",
        "  return False\n",
        "\n",
        "#verificar maior valor na lista\n",
        "def maiorValor(lista):\n",
        "\n",
        "  maiorValor = 0\n",
        "  for item in lista:\n",
        "    if item > maiorValor:\n",
        "        maiorValor = item\n",
        "\n",
        "  return maiorValor\n",
        "\n",
        "#verificar possivel similaridade no cabeçalho dos dicionários INFO\n",
        "def checkAVGSimilaritiesINFO(dicTableGT, dicTable, percTolerancia):\n",
        "\n",
        "  qtdColGT = len(dicTableGT[\"HEAD\"])\n",
        "  qtdColTab = len(dicTable[\"HEAD\"])\n",
        "\n",
        "  arrSim = []\n",
        "  arrSummary = []\n",
        "  limit = 4\n",
        "\n",
        "  #verificar similaridade nas 3 primeiras colunas\n",
        "  for i in range(qtdColTab):\n",
        "\n",
        "    for j in range(qtdColGT):\n",
        "      strTab = dicTable[\"HEAD\"][i]\n",
        "      strGT = dicTableGT[\"HEAD\"][j]\n",
        "      arrSim.append(calcPercSimStrings(strTab, strGT))\n",
        "\n",
        "    arrSummary.append(maiorValor(arrSim))\n",
        "    arrSim = []\n",
        "\n",
        "    if(i>= limit):\n",
        "      break\n",
        "\n",
        "  #print(arrSummary)\n",
        "  avgPerc = sum(arrSummary) / len(arrSummary)\n",
        "  return avgPerc >= percTolerancia\n",
        "\n",
        "\n",
        "#verificar possivel similaridade no cabeçalho dos dicionários FIRST_LINE\n",
        "def checkAVGSimilarities2INFO(dicTableGT, dicTable, percTolerancia):\n",
        "\n",
        "  qtdColGT = len(dicTableGT[\"FIRST_LINE\"])\n",
        "  qtdColTab = len(dicTable[\"FIRST_LINE\"])\n",
        "\n",
        "  arrSim = []\n",
        "  arrSummary = []\n",
        "  limit = 3\n",
        "\n",
        "  #verificar similaridade nas 3 primeiras colunas\n",
        "  for i in range(qtdColTab):\n",
        "\n",
        "    for j in range(qtdColGT):\n",
        "      strTab = dicTable[\"FIRST_LINE\"][i]\n",
        "      strGT = dicTableGT[\"FIRST_LINE\"][j]\n",
        "      arrSim.append(calcPercSimStrings(strTab, strGT))\n",
        "\n",
        "    arrSummary.append(maiorValor(arrSim))\n",
        "    arrSim = []\n",
        "\n",
        "    if(i>= limit):\n",
        "      break\n",
        "\n",
        "  #print(arrSummary)\n",
        "  avgPerc = sum(arrSummary) / len(arrSummary)\n",
        "  return avgPerc >= percTolerancia\n",
        "\n",
        "def getDicTableInfo(labName, curfile, page, qtdlinhas, qtdcolunas, bbox, head, firstLine):\n",
        "  dicTableInfo = {}\n",
        "\n",
        "  dicTableInfo[\"LAB\"] = labName\n",
        "  dicTableInfo[\"FILE\"] = curfile\n",
        "  dicTableInfo[\"PAGE\"] = page\n",
        "  dicTableInfo[\"TABLEID\"] = \"TBD\"\n",
        "  dicTableInfo[\"DIMENSION\"] = str(qtdlinhas) + \"X\" + str(qtdcolunas)\n",
        "  dicTableInfo[\"BBOX\"] = bbox\n",
        "  dicTableInfo[\"HEAD\"] = head\n",
        "  dicTableInfo[\"FIRST_LINE\"] = firstLine\n",
        "\n",
        "  return dicTableInfo\n",
        "\n",
        "def SaveDicTableInfo (filePath, dicTableInfo):\n",
        "\n",
        "  strFile = \"{\"\n",
        "  lenDic = len(dicTableInfo.items())\n",
        "  #print(lenDic)\n",
        "  i = 0\n",
        "  for chave, valor in dicTableInfo.items():\n",
        "    vir = \",\" if i < lenDic-1 else \"\"\n",
        "    if type(valor) == str:\n",
        "      strFile += \"'\" + str(chave)+ \"':'\" + str(valor) + \"'\" + vir + \"\\n\"\n",
        "    else:\n",
        "      strFile += \"'\" + str(chave) + \"':\" + str(valor) + vir + \"\\n\"\n",
        "    i = i + 1\n",
        "\n",
        "  strFile += \"}\"\n",
        "  with open(filePath, 'w') as arquivo:\n",
        "    arquivo.write(strFile)\n",
        "\n",
        "#numero de ocorrencias de um numero em uma lista\n",
        "def numTimes(list, num):\n",
        "\n",
        "  cont = 0\n",
        "  for valor in list:\n",
        "    if valor == num:\n",
        "      cont+=1\n",
        "\n",
        "  return cont\n",
        "\n",
        "def isDecimal(valor):\n",
        "  try:\n",
        "\n",
        "    if valor == \"NAN\" or valor == \"nan\":\n",
        "      return False\n",
        "    else:\n",
        "      float(valor)\n",
        "      return True\n",
        "  except ValueError:\n",
        "      return False\n",
        "'''\n",
        "#calcular similaridades em valores das celulas bbox e tokens de duas listas de tabelas\n",
        "def calStatsTablesValues(lstTable1, lstTable2):\n",
        "\n",
        "  lstResTokens = []\n",
        "  lstResBbox = []\n",
        "  for item1, item2 in zip(lstTable1, lstTable2):\n",
        "    listaBbox1 = item1[\"bbox\"]\n",
        "    listaBbox2 = item2[\"bbox\"]\n",
        "    str1 = \"\".join(item1[\"tokens\"])\n",
        "    str2 = \"\".join(item2[\"tokens\"])\n",
        "\n",
        "    lstResBbox.append(round(calcPercSimValueLists(listaBbox1, listaBbox2),2))\n",
        "    strDec1 = str1.replace(\",\", \".\").strip()\n",
        "    strDec2 = str2.replace(\",\", \".\").strip()\n",
        "    #se os valores forem numeros converter para float para calcular similiaridade com maior exatidao\n",
        "    if (isDecimal(strDec1) and isDecimal(strDec2)):\n",
        "      lstResTokens.append( round( calcPercSimValueNums(float(strDec1), float(strDec2) ),2) )\n",
        "    #no caso de string\n",
        "    else:\n",
        "      lstResTokens.append(round(calcPercSimStrings(str1, str2),2))\n",
        "\n",
        "  return lstResTokens, lstResBbox\n",
        "\n",
        "'''\n",
        "def noteTokensHTML(df):\n",
        "\n",
        "  lsthead = []\n",
        "  lsttd = []\n",
        "  hasheader = False\n",
        "  hasdata = False\n",
        "  dict_tokens_html = {}\n",
        "  lsthead\n",
        "\n",
        "  #percorre o dataframe para construir a estrutura html de colunas\n",
        "  for i in range(len(df)):\n",
        "    primeiraColuna = True\n",
        "    j = 0\n",
        "    for column in df.columns:\n",
        "        #primeira linha sao os cabeçalhos\n",
        "        if i == 0:\n",
        "          hasheader = True\n",
        "          lsthead.append(\"<td>\")\n",
        "          lsthead.append(df.at[i,column].replace(\"'\",\"\")) #apenas para teste, comentar depois\n",
        "          lsthead.append(\"</td>\")\n",
        "        else:\n",
        "          hasdata = True\n",
        "          if(primeiraColuna):\n",
        "            primeiraColuna = False\n",
        "            #a partir da 3a linha fecha a linha anterior </tr>\n",
        "            if(j==0 and i > 1):\n",
        "              lsttd.append(\"</tr>\")\n",
        "            lsttd.append(\"<tr>\")\n",
        "          lsttd.append(\"<td>\")\n",
        "          lsttd.append(df.at[i,column].replace(\"'\",\"\")) #apenas para teste, comentar depois\n",
        "          lsttd.append(\"</td>\")\n",
        "\n",
        "        primeiraColuna = False\n",
        "        j = j + 1\n",
        "\n",
        "  if(hasheader):\n",
        "    lsthead.insert(0,\"<thead>\")\n",
        "    lsthead.insert(1,\"<tr>\")\n",
        "    lsthead.append(\"</tr>\")\n",
        "    lsthead.append(\"</thead>\")\n",
        "\n",
        "  if(hasdata):\n",
        "    lsttd.insert(0,\"<tbody>\")\n",
        "    lsttd.append(\"</tbody>\")\n",
        "\n",
        "  #se a estrutura tiver completa, adiciona no dicionario tokens\n",
        "  if(hasheader and hasdata):\n",
        "    lsthead.extend(lsttd)\n",
        "  else:\n",
        "    dict_tokens_html = {\"tokens\": \"vazio\"}\n",
        "    lsthead.extend(dict_tokens_html)\n",
        "\n",
        "  lsthead.insert(0,\"<table>\")\n",
        "  lsthead.extend(\"</table>\")\n",
        "  return lsthead\n",
        "\n",
        "\n",
        "def noteListTokensBbox(cell_coordinates, lstData, lstTableRef):\n",
        "  list_tokens_bbox = []\n",
        "\n",
        "  #dimensao dos dados\n",
        "  qtdRowData = len(lstData)\n",
        "  qtdColData = len(lstData[0])\n",
        "  print(\"dimensao Data {0} x {1} \".format(qtdRowData, qtdColData))\n",
        "\n",
        "  #carregando BBOX de cada celula por linha para uma lista\n",
        "  qtdlinhasBbox = len(cell_coordinates)\n",
        "  qtdcolunasBbox = len(cell_coordinates[0][\"cells\"])\n",
        "  print(\"dimensao Bbox {0} x {1} \".format(qtdlinhasBbox, qtdcolunasBbox))\n",
        "\n",
        "\n",
        "  i = 0\n",
        "  for row in cell_coordinates:\n",
        "    j = 0\n",
        "    for bbox in row[\"cells\"]:\n",
        "      x1 = round(bbox[\"cell\"][0])\n",
        "      y1 = round(bbox[\"cell\"][1])\n",
        "      x2 = round(bbox[\"cell\"][2])\n",
        "      y2 = round(bbox[\"cell\"][3])\n",
        "\n",
        "      if(lstTableRef is None):\n",
        "        dict_tokens_bbox = {'tokens': list(lstData[i][j]), 'bbox': [x1, y1, x2, y2]}\n",
        "      else:\n",
        "        dict_tokens_bbox = {'tokens': list(lstData[i][j]), 'bbox': [x1 - lstTableRef[0], y1 - lstTableRef[1], x2 - lstTableRef[0], y2 - lstTableRef[1]]}\n",
        "      list_tokens_bbox.append(dict_tokens_bbox)\n",
        "      j+=1\n",
        "    i+=1\n",
        "\n",
        "  return list_tokens_bbox\n",
        "\n",
        "def printMetaDados(dicMetaData):\n",
        "\n",
        "  strout = []\n",
        "  strout.append(\"{ \\n\")\n",
        "\n",
        "  if \"filename\" in dicMetaData:\n",
        "    strout.append(\"filename: '\" + str(dicMetaData[\"filename\"]) + \"',\\n\")\n",
        "  else:\n",
        "    strout[0] = \"chave filename não existe na estrutura\"\n",
        "    return strout\n",
        "\n",
        "  if \"split\" in dicMetaData:\n",
        "    strout.append(\"split: '\" + str(dicMetaData[\"split\"]) + \"',\\n\")\n",
        "  else:\n",
        "    strout[0] = \"chave split não existe na estrutura\"\n",
        "    return strout\n",
        "\n",
        "  if \"imgid\" in dicMetaData:\n",
        "    strout.append(\"'imgid': \" + str(dicMetaData[\"imgid\"]) + \",\\n\")\n",
        "  else:\n",
        "    strout[0] = \"chave imgid não existe na estrutura\"\n",
        "    return strout\n",
        "\n",
        "  if \"html\" in dicMetaData:\n",
        "\n",
        "    strout.append(\"--INICIO HTML \\n\")\n",
        "    strout.append(\"'html': \\n {\")\n",
        "\n",
        "    if \"cells\" in dicMetaData[\"html\"] and \"structure\" in dicMetaData[\"html\"]:\n",
        "\n",
        "      if isinstance(dicMetaData[\"html\"][\"cells\"], list ) and isinstance(dicMetaData[\"html\"][\"structure\"], list ):\n",
        "\n",
        "        #varrendo o conteudo da lista dicMetaData[\"html\"][\"cells\"]\n",
        "        #que contem as duas sublistas tokens e bbox\n",
        "        strout.append(\"--INICIO CELLS \\n\")\n",
        "        strout.append(\"'cells': [\\n\")\n",
        "        i = 0\n",
        "        for arrcells in dicMetaData[\"html\"][\"cells\"]:\n",
        "\n",
        "           #print da estrutura dos dicionarios tokens e bbox\n",
        "           tokens =  arrcells[\"tokens\"]\n",
        "           bbox =  arrcells[\"bbox\"]\n",
        "           comma = \",\"\n",
        "           if i == len(dicMetaData[\"html\"][\"cells\"]) -1:\n",
        "            comma = \"\"\n",
        "           else:\n",
        "            comma = \",\"\n",
        "\n",
        "           strout.append(\"      {'tokens': \" + str(tokens) + \", 'bbox': \" + str(bbox) + \"}\" + comma + \" \\n\")\n",
        "           i = i + 1\n",
        "\n",
        "        strout.append(\"] --FIM CELLS\\n\")\n",
        "\n",
        "        #print da estrutura do dicionario structure\n",
        "        if(dicMetaData[\"html\"] is not None and dicMetaData[\"html\"][\"structure\"] is not None):\n",
        "          #strout.append(\"      'structure': [\" + str(\"','\".join(dicMetaData[\"html\"][\"structure\"])) + \"' \\n\")\n",
        "          strout.append(\"      'structure': ['\" + str(\"','\".join([x for x in dicMetaData[\"html\"][\"structure\"] if x is not None])) + \"' \\n\")\n",
        "\n",
        "        else:\n",
        "          strout.append(\"      'structure': ['None'] \\n\")\n",
        "\n",
        "\n",
        "        strout.append(\"] --FIM STRUCTURE \\n\")\n",
        "\n",
        "      else:\n",
        "        strout[0] = \"chave html/cells ou structure não existe na estrutura\"\n",
        "        return strout\n",
        "\n",
        "    strout.append(\"} --FIM HTML\\n\")\n",
        "  else:\n",
        "    strout[0] = \"chave html não existe na estrutura\"\n",
        "    return strout\n",
        "\n",
        "  strout.append(\"} \\n\")\n",
        "  return strout\n",
        "\n",
        "def saveAnnotationFile(dicMetaData, dirout , numPage):\n",
        "\n",
        "  vecArq = dicMetaData[\"filename\"].split(\"/\")\n",
        "\n",
        "  nomeArq = \"\"\n",
        "  if(len(vecArq)>0):\n",
        "\n",
        "    tableID = dicMetaData[\"imgid\"].replace(\"'\",\"\")\n",
        "    filename = vecArq[len(vecArq)-1].split(\".\")[0]\n",
        "    labname = vecArq[len(vecArq)-2].split(\".\")[0]\n",
        "\n",
        "    nomeArq = tableID + \"|\" + filename + \"|\" + str(numPage) + \"_METADADOS.mtd\"\n",
        "    print(\"gravando arquivo \", nomeArq)\n",
        "\n",
        "    strout = printMetaDados(dicMetaData)\n",
        "\n",
        "    labDirOut = dirout + \"/\" + labname + \"/\"\n",
        "    if not os.path.exists(labDirOut):\n",
        "      os.makedirs(labDirOut)\n",
        "\n",
        "    with open(labDirOut + nomeArq, 'w') as arquivo:\n",
        "      for linha in strout:\n",
        "            arquivo.write(linha)\n",
        "\n",
        "def getPos(lst, key):\n",
        "\n",
        "  for k, item in enumerate(lst):\n",
        "    if item == key:\n",
        "      return k\n",
        "\n",
        "  return -1\n",
        "\n",
        "#FUNCAO DE VERIFICA SE EXISTE O BUG DE TRUNCAR O VALOR ∞\n",
        "def isBUGInfinito(dicTable, dicTableGT):\n",
        "\n",
        "  char = \"\"\n",
        "  posInf = getPos(dicTableGT[\"FIRST_LINE\"], \"∞\")\n",
        "  posInfV = getPos(dicTableGT[\"FIRST_LINE\"], \"V\")\n",
        "\n",
        "  #possui valor ∞ na tabela? segue análise\n",
        "  if posInf >-1:\n",
        "    char = \"∞\"\n",
        "    print(\"Possui valor ∞ na tabela, posInf\", posInf)\n",
        "    #2 - possuem o mesmo valor de dimensao em DIMENSION\n",
        "    if dicTable[\"DIMENSION\"] == dicTableGT[\"DIMENSION\"]:\n",
        "      print(\"Valor DIMENSION iguais\")\n",
        "      #4 primeiras colunas das duas tabelas possuem o mesmo valor?\n",
        "      print(\"checkAVGSimilarities2INFO >=60 perc? \",checkAVGSimilarities2INFO(dicTableGT, dicTable, 80))\n",
        "      if checkAVGSimilarities2INFO(dicTableGT, dicTable, 60):\n",
        "        print(\"Quatro primeiras colunas similares\")\n",
        "        #4 - chave HEAD tem o tamanho um a menos que GT\n",
        "        if len(dicTable[\"HEAD\"]) == len(dicTableGT[\"HEAD\"])-1 and len(dicTable[\"FIRST_LINE\"]) == len(dicTableGT[\"FIRST_LINE\"])-1:\n",
        "          #dicTable[\"FIRST_LINE\"].insert(posInf, \"∞\")\n",
        "          return True, posInf, \"∞\"\n",
        "\n",
        "  #possui valor ∞ na tabela? segue análise\n",
        "  if posInfV >-1:\n",
        "    char = \"V\"\n",
        "    print(\"Possui valor V na tabela, posInf\", posInf)\n",
        "    #2 - possuem o mesmo valor de dimensao em DIMENSION\n",
        "    if dicTable[\"DIMENSION\"] == dicTableGT[\"DIMENSION\"]:\n",
        "      print(\"Valor DIMENSION iguais\")\n",
        "      #4 primeiras colunas das duas tabelas possuem o mesmo valor?\n",
        "      print(\"checkAVGSimilarities2INFO >=60 perc? \",checkAVGSimilarities2INFO(dicTableGT, dicTable, 80))\n",
        "      if checkAVGSimilarities2INFO(dicTableGT, dicTable, 60):\n",
        "        print(\"Quatro primeiras colunas similares\")\n",
        "        #4 - chave HEAD tem o tamanho um a menos que GT\n",
        "        if len(dicTable[\"HEAD\"]) == len(dicTableGT[\"HEAD\"])-1 and len(dicTable[\"FIRST_LINE\"]) == len(dicTableGT[\"FIRST_LINE\"])-1:\n",
        "          #dicTable[\"FIRST_LINE\"].insert(posInf, \"∞\")\n",
        "          return True, posInfV, \"V\"\n",
        "\n",
        "  return False, -1, \"\"\n",
        "\n",
        "import glob\n",
        "\n",
        "def deleteFiles(dir, ext):\n",
        "  # Obter todos os arquivos com a extensão especificada\n",
        "  files = glob.glob(os.path.join(dir, f'*.{ext}'))\n",
        "\n",
        "  # Remover cada arquivo encontrado\n",
        "  for file in files:\n",
        "      try:\n",
        "          os.remove(file)\n",
        "          print(f\"Arquivo {file} removido com sucesso.\")\n",
        "      except OSError as e:\n",
        "          print(f\"Erro ao remover o arquivo {file}: {e}\")\n",
        "\n",
        "def printHTML2(lst, tipo): #com TAB\n",
        "  # tipo: RAW (cru) ou PRETTY (html com identações)\n",
        "\n",
        "  strout = \"\"\n",
        "  #strres = ''.join(lst)\n",
        "  strres = ''.join([str(x) for x in lst])\n",
        "  if tipo == \"PRETTY\":\n",
        "    soup = bs(strres, 'html.parser')\n",
        "    strout = soup.prettify()\n",
        "    # Substituir espaços por TAB\n",
        "    strout = strout.replace(\"  \", \"\\t\")\n",
        "  else:\n",
        "    strout = strres\n",
        "\n",
        "  return strout\n",
        "\n",
        "def printElementMetaData(dicMetaData, elem):\n",
        "\n",
        "  strout = []\n",
        "  strout.append(\"[\")\n",
        "\n",
        "  if not \"filename\" in dicMetaData:\n",
        "    strout[0] = \"chave filename não existe na estrutura\"\n",
        "    return strout\n",
        "\n",
        "  if not \"split\" in dicMetaData:\n",
        "    strout[0] = \"chave split não existe na estrutura\"\n",
        "    return strout\n",
        "\n",
        "  if not \"imgid\" in dicMetaData:\n",
        "    strout[0] = \"chave imgid não existe na estrutura\"\n",
        "    return strout\n",
        "\n",
        "  if \"html\" in dicMetaData:\n",
        "    if \"cells\" in dicMetaData[\"html\"] and \"structure\" in dicMetaData[\"html\"]:\n",
        "      if isinstance(dicMetaData[\"html\"][\"cells\"], list ) and isinstance(dicMetaData[\"html\"][\"structure\"], list ):\n",
        "\n",
        "        i = 0\n",
        "\n",
        "        if(elem == \"BBOX\"):\n",
        "          #strout.append(\"{\")\n",
        "          for arrcells in dicMetaData[\"html\"][\"cells\"]:\n",
        "\n",
        "            tokens =  arrcells[\"tokens\"]\n",
        "            bbox =  arrcells[\"bbox\"]\n",
        "            comma = \",\"\n",
        "            if i == len(dicMetaData[\"html\"][\"cells\"]) -1:\n",
        "              comma = \"\"\n",
        "            else:\n",
        "              comma = \",\"\n",
        "\n",
        "            strout.append(\"{'tokens': \" + str(tokens) + \", 'bbox': \" + str(bbox) + \"}\" + comma + \" \\n\")\n",
        "            i = i + 1\n",
        "\n",
        "        elif(elem == \"HTML_PRETTY\"):\n",
        "          strout.append(printHTML2(dicMetaData[\"html\"][\"structure\"], \"PRETTY\"))\n",
        "\n",
        "        else:\n",
        "          html = \"'\"\n",
        "          html = html + \"','\".join([element for element in dicMetaData[\"html\"][\"structure\"] if element]) + \"'\"\n",
        "          strout.append(html)\n",
        "\n",
        "      else:\n",
        "        strout[0] = \"chave html/cells ou structure não existe na estrutura\"\n",
        "        return strout\n",
        "\n",
        "  else:\n",
        "    strout[0] = \"chave html não existe na estrutura\"\n",
        "    return strout\n",
        "\n",
        "  strout.append(\"]\")\n",
        "  return strout\n",
        "\n",
        "def saveElementMetadata(dicMetaData, elem, dirout, numPage):\n",
        "\n",
        "  vecArq = dicMetaData[\"filename\"].split(\"/\")\n",
        "  #print(vecArq)\n",
        "  nomeArq = \"\"\n",
        "  if(len(vecArq)>0):\n",
        "\n",
        "    tableID = str(dicMetaData[\"imgid\"]).replace(\"'\",\"\")\n",
        "    filename = vecArq[len(vecArq)-1].split(\".\")[0]\n",
        "    labname = vecArq[len(vecArq)-2].split(\".\")[0]\n",
        "\n",
        "    nomeArq = tableID + \"|\" + filename + \"|\" + str(numPage) + \"_\" + elem + \".\" + elem.lower()\n",
        "    strout = printElementMetaData(dicMetaData, elem)\n",
        "\n",
        "    labDirOut = dirout + \"/\" + labname + \"/\"\n",
        "\n",
        "    print(\"Arquivo de anotação \", elem, \" gerado = \",  nomeArq)\n",
        "    with open(labDirOut + nomeArq, 'w') as arquivo:\n",
        "      for linha in strout:\n",
        "          arquivo.write(linha)\n",
        "\n",
        "#retorna o tableID de maior similiaridade entre os dicionarios GT de comparacao\n",
        "def getMaiorSimilaridade(dic, listasGT):\n",
        "\n",
        "  lstDicRes = []\n",
        "\n",
        "  for dicGT in listasGT:\n",
        "\n",
        "    lstRes = []\n",
        "\n",
        "    #ajusta caso necessário a dimensao entre as tabelas\n",
        "    #print(\"a tratar...\", dic[\"FIRST_LINE\"])\n",
        "    #print(type(dic[\"FIRST_LINE\"]))\n",
        "    dic[\"FIRST_LINE\"] = ajustColList(dic[\"FIRST_LINE\"], len(dicGT[\"FIRST_LINE\"]))\n",
        "    lenDic = len(dic[\"FIRST_LINE\"])\n",
        "\n",
        "    print(\"getMaiorSimilaridade, FIRST_LINE GT\", dicGT[\"FIRST_LINE\"])\n",
        "    print(\"getMaiorSimilaridade, FIRST_LINE ANALISE\", dic[\"FIRST_LINE\"])\n",
        "    for i in range(len(dicGT[\"FIRST_LINE\"])):\n",
        "\n",
        "      lenDicGT = len(dicGT[\"FIRST_LINE\"])\n",
        "\n",
        "      if lenDic != lenDicGT: #tamanhos diferentes, retornar vazio\n",
        "        return \"\"\n",
        "\n",
        "      str1 = dic[\"FIRST_LINE\"][i]\n",
        "      str2 = dicGT[\"FIRST_LINE\"][i]\n",
        "      strDec1 = str1.replace(\",\", \".\").strip()\n",
        "      strDec2 = str2.replace(\",\", \".\").strip()\n",
        "\n",
        "      #se os valores forem numeros converter para float para calcular similiaridade com maior exatidao\n",
        "      if (isDecimal(strDec1) and isDecimal(strDec2)):\n",
        "        #print(\" Similaridade entre dois numeros \", strDec1, \" e \", strDec2, \" = \", round(calcPercSimValueNums(float(strDec1), float(strDec2)), 2))\n",
        "        lstRes.append(round(calcPercSimValueNums(float(strDec1), float(strDec2)), 2))\n",
        "      #no caso de string\n",
        "      else:\n",
        "        #print(\" Similaridade entre duas strings \", strDec1, \" e \", strDec2, \" = \", round(calcPercSimStrings(str1, str2),4))\n",
        "        lstRes.append(round(calcPercSimStrings(str1, str2),2))\n",
        "\n",
        "    lstDicRes.append({\"TABLEID\": dicGT[\"TABLEID\"], \"RESULT\":lstRes})\n",
        "\n",
        "  #verificando maior media\n",
        "  tableId = \"\"\n",
        "  maiorMedia = 0\n",
        "  for dicRes in lstDicRes:\n",
        "    avg = sum(dicRes[\"RESULT\"]) / len(dicRes[\"RESULT\"])\n",
        "    print(\"Media \", avg)\n",
        "    if avg > maiorMedia:\n",
        "      tableId = dicRes[\"TABLEID\"]\n",
        "      maiorMedia = avg\n",
        "\n",
        "  return tableId\n",
        "\n",
        "def ajustColList(lst1, qtdColsRef):\n",
        "\n",
        "  # Calcula o número de colunas de cada lista\n",
        "  #num_cols_lstRef = len(lstRef)\n",
        "  num_cols_lst1 = len(lst1) if lst1 else 0\n",
        "\n",
        "  # Se lst1 tiver menos colunas que lstRef, preenche com NaN\n",
        "  if num_cols_lst1 < qtdColsRef:\n",
        "    # Calcula o número de colunas a serem adicionadas\n",
        "    num_cols_adicionais = qtdColsRef - num_cols_lst1\n",
        "    # Preenche lst2 com NaN nas novas colunas\n",
        "\n",
        "    #print(\"num_cols_adicionais \", num_cols_adicionais)\n",
        "    for i in range(num_cols_adicionais):\n",
        "      lst1.append(\"NAN\")\n",
        "\n",
        "  #se lst1 tiver mais coluna que lstRef, remove as colunas adicionais de lst1\n",
        "  elif num_cols_lst1 > qtdColsRef:\n",
        "    # Calcula o número de colunas a serem removidas\n",
        "    num_cols_adicionais = num_cols_lst1 - qtdColsRef\n",
        "    for i in range(num_cols_adicionais):\n",
        "      if (len(lst1)>0):\n",
        "        del(lst1[len(lst1)-1])\n",
        "\n",
        "  return lst1\n",
        "\n",
        "#funcao para ajustar uma lista de acordo com a quantidade de linhas e colunas de referencia\n",
        "# se tiver a mais linhas ou colunas, adiciona, se tiver menos, remove\n",
        "def ajustList(lst1, qtdRowsRef, qtdColsRef):\n",
        "\n",
        "  qtdRows = len(lst1)\n",
        "\n",
        "  #lsteste = eval(strdata)\n",
        "  lst1_ajust = []\n",
        "\n",
        "  #1 - ajustando as colunas\n",
        "  for lstRow in lst1:\n",
        "    lst1_ajust.append(ajustColList(lstRow, qtdColsRef))\n",
        "\n",
        "  #1 - ajustando as linhas\n",
        "  #se precisar adicionar linhas\n",
        "  if(qtdRowsRef > qtdRows):\n",
        "    qtdLinhasAdicionais = qtdRowsRef - qtdRows\n",
        "    for i in range(qtdLinhasAdicionais):\n",
        "      if len(lst1_ajust) >0 and len(lst1_ajust[0]) >0:\n",
        "        lst1_ajust.insert(len(lst1_ajust), [\"NAN\" for _ in range(len(lst1_ajust[0]))])\n",
        "  #se precisar remover linhas adicionais\n",
        "  elif(qtdRows > qtdRowsRef):\n",
        "    qtdLinhasAdicionais = qtdRows - qtdRowsRef\n",
        "    for i in range(qtdLinhasAdicionais):\n",
        "      del(lst1_ajust[len(lst1_ajust)-1])\n",
        "\n",
        "  return lst1_ajust\n",
        "\n",
        "#funcao para ajustar a estrutura cell_coordinates em relacao a referencia para possibilitar a comparacao e geracao de estatisticas\n",
        "def ajustCellCord (cellCord, qtdRowsRef, qtdColsRef):\n",
        "\n",
        "  lstCoord = [999999, 999999, 999999, 999999] #nova lista de coordenadas\n",
        "  dicNewCol = {'column': lstCoord, 'cell': lstCoord} #uma nova coluna (celula)\n",
        "  #nova linha da tabela\n",
        "  newLine =  \"{'row': [99999, 99999, 99999, 99999], \\\n",
        "              'cells': [], \\\n",
        "              'cell_count': 0}\"\n",
        "  dicNewLine = eval(newLine)\n",
        "\n",
        "  #verificando dimensao da estrutura atual\n",
        "  qtdRows = 0\n",
        "  qtdCols = 0\n",
        "  if cellCord is not None and len(cellCord) >0:\n",
        "    qtdRows = len(cellCord)\n",
        "    qtdCols = len(cellCord[0][\"cells\"])\n",
        "  #qtdRows = len(cellCord)\n",
        "  #qtdCols = len(cellCord[0][\"cells\"])\n",
        "\n",
        "  #adicionando estrutura inicial para cada quantidade de colunas de referencia\n",
        "  for i in range(qtdColsRef):\n",
        "    dicNewLine[\"cells\"].insert(i,dicNewCol)\n",
        "\n",
        "  #adiciona para cada coluna adicional necessária\n",
        "  if qtdCols < qtdColsRef:\n",
        "    qtdColAdicionais = qtdColsRef - qtdCols\n",
        "\n",
        "    print(\"Adicionando coluna, qtd = \", qtdColAdicionais)\n",
        "    for i in range(qtdColAdicionais):\n",
        "      for row in cellCord:\n",
        "        row['cells'].append(dicNewCol)\n",
        "\n",
        "  #removendo uma coluna para cada adicional\n",
        "  elif qtdCols > qtdColsRef:\n",
        "    qtdColAdicionais = qtdCols - qtdColsRef\n",
        "\n",
        "    print(\"Removendo coluna, qtd = \", qtdColAdicionais)\n",
        "    for i in range(qtdColAdicionais):\n",
        "      for row in cellCord:\n",
        "        row['cells'] = row['cells'][:-1]\n",
        "\n",
        "  #adiciona linha para cada linha adicional necessária\n",
        "  if qtdRows < qtdRowsRef:\n",
        "    qtdRowAdicionais = qtdRowsRef - qtdRows\n",
        "\n",
        "    print(\"Adicionando linha, qtd = \", qtdRowAdicionais)\n",
        "    for i in range(qtdRowAdicionais):\n",
        "      cellCord.append(dicNewLine)\n",
        "\n",
        "  #removendo linha para cada linha adicional necessária\n",
        "  elif qtdRows > qtdRowsRef:\n",
        "    qtdRowAdicionais = qtdRows - qtdRowsRef\n",
        "\n",
        "    print(\"Removendo linha, qtd = \", qtdRowAdicionais)\n",
        "    #removendo linha para cada adicional\n",
        "    for i in range(qtdRowAdicionais):\n",
        "      del(cellCord[len(cellCord)-1])\n",
        "\n",
        "  return cellCord\n",
        "\n",
        "def temRepeticoes(lista):\n",
        "    return len(lista) != len(set(lista))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W3JnabqJwbCJ"
      },
      "source": [
        "Pré-processamento (preparação dos modelos)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KfNPXNa3wapt"
      },
      "outputs": [],
      "source": [
        "#modelo 1 de deteccao de tabela - normalizando hiperparametros de entrada\n",
        "import easyocr\n",
        "\n",
        "#preparando processadores para modelo\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "reader = easyocr.Reader(['en']) # this needs to run only once to load the model into memory\n",
        "\n",
        "############ MODELO 1 - DETEÇÃO DE TABELA ------- ##############\n",
        "\n",
        "#modelo para detectar as tabelas\n",
        "model = AutoModelForObjectDetection.from_pretrained(\"microsoft/table-transformer-detection\", revision=\"no_timm\")\n",
        "model.to(device)\n",
        "\n",
        "detection_transform = transforms.Compose([\n",
        "    MaxResize(800),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "############ MODELO 2 - ESTRUTURA DE TABELA ------- ##############\n",
        "\n",
        "structure_model = TableTransformerForObjectDetection.from_pretrained(\"microsoft/table-structure-recognition-v1.1-all\")\n",
        "structure_model.to(device)\n",
        "\n",
        "structure_transform = transforms.Compose([\n",
        "    MaxResize(1000),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "])\n",
        "clear_output()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0quGP3rhzvsY"
      },
      "source": [
        "# FUNCAO PRINCIPAL - GERAR ARQUIVOS DE METADADOS, BBOX E HTML"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "txKZDCMSJ5rK"
      },
      "outputs": [],
      "source": [
        "################################### FUNCAO PRINCIPAL - GERAR ARQUIVOS DE METADADOS #######################\n",
        "\n",
        "dfArq = listFiles(CERT_PATH, None) # carregar a lista de arquivos no DATAFRAME\n",
        "\n",
        "reader = easyocr.Reader(['en']) # this needs to run only once to load the model into memory\n",
        "\n",
        "# Definir o fuso horário de SP\n",
        "fuso_horario_brasilia = pytz.timezone('America/Sao_Paulo')\n",
        "\n",
        "#varrendo cada arquivo\n",
        "#varrendo cada pagina do arquivo\n",
        "#lst = [{'PATH':'/content/drive/MyDrive/DataSets/Certificados/In/LAB_02_PRESERTEC/009.pdf', \"QTDPAGES\":2}]\n",
        "#dfArq = pd.DataFrame(lst)\n",
        "\n",
        "pathLab = DIROUT_PUBTABLES + \"/\" + LAB_PATH + \"/\"\n",
        "\n",
        "if(os.path.exists(pathLab)):\n",
        "  print('Removendo arquivos gerados anteriormente.., caminho:', pathLab)\n",
        "  deleteFiles2(pathLab) #deletando os arquivos anteriores\n",
        "\n",
        "for filepath, pages in zip(dfArq[\"PATH\"], dfArq[\"QTDPAGES\"]):\n",
        "\n",
        "  arrcurfile = filepath.split(\"/\")\n",
        "  curFile = arrcurfile[len(arrcurfile)-1]\n",
        "  labName = arrcurfile[len(arrcurfile)-2]\n",
        "\n",
        "  #inicializando variaveis GT\n",
        "  listFilesGT = []\n",
        "  listTablesInfoGT = []\n",
        "\n",
        "  #coletando dados das tabelas GT para comparacao e gerar o ID da imagem correto\n",
        "  GT_LAB_OUT = GT_PATH + \"/\" + labName + \"/\"\n",
        "\n",
        "  #varrendo cada pagina do arquivo\n",
        "  for i in range(int(pages)):\n",
        "\n",
        "    page = i+1\n",
        "    #verificando a quantidade de tabelas por pagina\n",
        "\n",
        "    #verificando se a pasta do laboratorio existe, caso negativo, cria\n",
        "    labDirOut = DIROUT_PUBTABLES + \"/\" + labName + \"/\"\n",
        "    if not os.path.exists(labDirOut):\n",
        "      os.makedirs(labDirOut)\n",
        "\n",
        "    #definindo variaveis para gravacao do arquivo de saida\n",
        "    noExtension = curFile.replace(\".pdf\",\"\")\n",
        "    #arquivo de PDF de leitura\n",
        "    #path_pdf_in = dfArq[\"PATH\"][0]\n",
        "    path_pdf_in = filepath\n",
        "    #caminho para arquivo PNG convertido\n",
        "    path_png_out =  labDirOut + labName + \"|\" + noExtension + \"|\" + str(page) + \".png\"\n",
        "    #caminho para arquivo PNG convertido e com melhoria de contraste e brilho\n",
        "    path_png_out_plus =  labDirOut + labName + \"|\" + noExtension + \"|\" + str(page) + \"_plus.png\"\n",
        "\n",
        "    ####1 - converter pdf para imagem  ####\n",
        "    pdf_page_to_png(path_pdf_in, page, path_png_out)\n",
        "\n",
        "    ####2 - melhorar a qualidade melhorar a qualidade da imagem#####\n",
        "    img_plus = aumentar_qualidade_e_contraste(path_png_out, 1, 5.5)\n",
        "    cv2.imwrite(path_png_out_plus, img_plus)\n",
        "\n",
        "    ####3 Carregar imagem para o modelo e tratar contraste\n",
        "    image = Image.open(path_png_out).convert(\"RGB\")\n",
        "\n",
        "    ####4 - PREPARAR IMAGEM PARA MODELO 1 (DETECÇÃO DE TABELA)\n",
        "    pixel_values = detection_transform(image).unsqueeze(0)\n",
        "    pixel_values = pixel_values.to(device)\n",
        "\n",
        "    model.to(device)\n",
        "    outputs = None\n",
        "    with torch.no_grad():\n",
        "      outputs = model(pixel_values)\n",
        "\n",
        "    #print(\"model.config.id2label \", model.config.id2label)\n",
        "    #print(\"pixel_values.shape \", pixel_values.shape)\n",
        "    #print(\"outputs.logits.shape \", outputs.logits.shape)\n",
        "\n",
        "    # update id2label to include \"no object\"\n",
        "    id2label = model.config.id2label\n",
        "    id2label[len(model.config.id2label)] = \"no object\"\n",
        "\n",
        "    #coletando coordenadas da tabela (bbox)\n",
        "    objects = outputs_to_objects(outputs, image.size, id2label)\n",
        "\n",
        "    tokens = []\n",
        "    detection_class_thresholds = {\n",
        "        \"table\": 0.5,\n",
        "        \"table rotated\": 0.5,\n",
        "        \"no object\": 10\n",
        "    }\n",
        "    crop_padding = 10\n",
        "\n",
        "    #tabelas coletadas do modelo TSR\n",
        "    tables_crops = objects_to_crops(image, tokens, objects, detection_class_thresholds, padding=0)\n",
        "\n",
        "    print(\"Arquivo: [\", path_pdf_in , \"] / qtd de tabelas para ler da pagina[\" + str(page) + \"]: \", len(tables_crops))\n",
        "\n",
        "    # FOR PARA CADA TABLE DA IMAGEM COLETADA\n",
        "    for j in range(len(tables_crops)):\n",
        "\n",
        "      #nova pagina, carrega a lista de referencia (GT) da pagina em questao\n",
        "      if j==0:\n",
        "        print(\"Novo page scan, carregando listTablesInfoGT....\")\n",
        "        listFilesGT = getListFilesGTInfo(noExtension, page, GT_LAB_OUT)\n",
        "        listTablesInfoGT = getListTablesInfo(GT_LAB_OUT,listFilesGT)\n",
        "\n",
        "      pathTable =  labDirOut + labName + \"|\" + noExtension + \"|\" + str(page) + \"|tab\" + str(j+1)\n",
        "\n",
        "      cropped_table = tables_crops[j]['image'].convert(\"RGB\")\n",
        "      cropped_table.save(\"table.jpg\")\n",
        "\n",
        "      ####5 - PREPARAR IMAGEM PARA MODELO 2 (ESTRUTURA DE TABELA)\n",
        "      pixel_values2 = structure_transform(cropped_table).unsqueeze(0)\n",
        "      pixel_values2 = pixel_values2.to(device)\n",
        "\n",
        "      # forward pass\n",
        "      outputs2 = None\n",
        "      with torch.no_grad():\n",
        "        outputs2 = structure_model(pixel_values2)\n",
        "\n",
        "      #==== 5 - GRAVANDO AS INFORMAÇÕES PARA O ARQUIVO INFO ======\n",
        "      # update id2label to include \"no object\"\n",
        "      structure_id2label = structure_model.config.id2label\n",
        "      structure_id2label[len(structure_id2label)] = \"no object\"\n",
        "\n",
        "      cells = outputs_to_objects(outputs2, cropped_table.size, structure_id2label)\n",
        "      cell_coordinates = get_cell_coordinates_by_row(cells)\n",
        "\n",
        "      qtdlinhas = 0\n",
        "      qtdcolunas = 0\n",
        "      if cell_coordinates is not None and len(cell_coordinates) >0:\n",
        "        qtdlinhas = len(cell_coordinates)\n",
        "        qtdcolunas = len(cell_coordinates[0][\"cells\"])\n",
        "\n",
        "      print(\"=============>Tabela pagina {0} caminho: {1} \".format(page,pathTable))\n",
        "      print(\"Dimensão cell_cordinates {0} x {1} \".format(qtdlinhas, qtdcolunas))\n",
        "\n",
        "      #CARREGANDO DADOS DA TABELA LIDA DO MODELO\n",
        "      data = apply_ocr(cell_coordinates)\n",
        "\n",
        "      #CARREGANDO E CORRIGINDO OS DADOS (CASO NECESSÁRIO)\n",
        "      lstData = []\n",
        "      for row, row_data in data.items():\n",
        "        lstData.append(row_data)\n",
        "\n",
        "      #print(\"objects\", objects)\n",
        "      #print(\"data\", data)\n",
        "      print(\"lstData\", lstData)\n",
        "      #print(\"cell_coordinates\", cell_coordinates)\n",
        "\n",
        "      qtdLinhasData = 0\n",
        "      qtdColunasData = 0\n",
        "      if(lstData is not None and len(lstData) >0):\n",
        "        qtdLinhasData = len(lstData)\n",
        "        qtdColunasData = len(lstData[0])\n",
        "\n",
        "      print(\"Dimensão lstData {0} x {1} \".format(qtdLinhasData, qtdColunasData))\n",
        "\n",
        "      #coletando o head e primeira linha da tabela para geração da tabela INFO\n",
        "      l = 0\n",
        "      lstHead = []\n",
        "      lstFirst = []\n",
        "      for row, row_data in data.items():\n",
        "        if l==0:\n",
        "          lstHead = list(row_data)\n",
        "        elif l==1:\n",
        "          lstFirst = list(row_data)\n",
        "        elif l==2: #(CASO NORMAL)\n",
        "          if numTimes(lstHead, \"\") > 2 or temRepeticoes(lstHead):\n",
        "            print(\"Possivel ocorrencia de cabeçalho, pulando 1.... ==> \",lstHead)\n",
        "            lstHead = copy.deepcopy(lstFirst)\n",
        "            lstFirst = list(row_data)\n",
        "        #elif l==2: #CASO ESPECIFICO PARA PRECISOTEC\n",
        "        #  #if numTimes(lstHead, \"\") > 2 or temRepeticoes(lstHead):\n",
        "        #  print(\"Pulando 2 casas (PRECISOTEC).... ==> \",lstHead)\n",
        "        #  lstHead = lstFirst\n",
        "        #  lstFirst = list(row_data)\n",
        "       #   break\n",
        "        else:\n",
        "          pass\n",
        "        l += 1\n",
        "\n",
        "      #print(\"dicTable HEAD antes\", dicTable[\"HEAD\"])\n",
        "      #print(\"dicTable FIRST_LINE antes\", dicTable[\"FIRST_LINE\"])\n",
        "\n",
        "      #gerando o dicionario para comparacao com GT\n",
        "      #esse bbox é da TABELA em si\n",
        "      bbox = [round(objects[j][\"bbox\"][0]), round(objects[j][\"bbox\"][1]), round(objects[j][\"bbox\"][2]), round(objects[j][\"bbox\"][3])]\n",
        "      dicTable = getDicTableInfo(labName, noExtension, page, qtdlinhas, qtdcolunas, bbox, lstHead, lstFirst)\n",
        "\n",
        "      #CASO 1 - VERIFICANDO SE TABELAS SAO IDENTICAS  (DE MESMA DIMENSAO)\n",
        "      #comparando o dicionario dos dados da tabela com a lista da GT para verificar qual ID será gerado\n",
        "      equalTables = False\n",
        "      for dicTableGT in listTablesInfoGT:\n",
        "        if checkDimensionINFO(dicTableGT, dicTable) and getPercSimTablesINFO(dicTableGT, dicTable , 75):\n",
        "          dicTable[\"TABLEID\"] = dicTableGT[\"TABLEID\"]\n",
        "          dicTable[\"DIMENSION\"] = dicTableGT[\"DIMENSION\"]\n",
        "          dicTable[\"OBS\"] = \"CASO 1 - TABELAS IDENTICAS\"\n",
        "          print(\"CASO 1 - TABELAS IDENTICAS, tableID \", dicTableGT[\"TABLEID\"])\n",
        "          equalTables = True\n",
        "          #remove da lista de dicionario o valor do tableid encontrado\n",
        "          listTablesInfoGT[:] = [dic for dic in listTablesInfoGT if dic.get(\"TABLEID\") != dicTable[\"TABLEID\"]]\n",
        "          break\n",
        "\n",
        "      #CASO 2 - BUG DO INFINITO (TABELA TRUNCADA DEVIDO A NAO RECONHECER SIMBOLO DO INFINITO\n",
        "      isBugInfinito = False\n",
        "      posInf = -1\n",
        "      if not equalTables:\n",
        "\n",
        "        for dicTableGT in listTablesInfoGT:\n",
        "          #print(\"CASO 2 - Comparacao, dicTableGT: \", dicTableGT)\n",
        "          #print(\"CASO 2 - Comparacao, dicTable antes: \", dicTable)\n",
        "\n",
        "          isBugInf, posInf, char = isBUGInfinito(dicTable, dicTableGT)\n",
        "          if isBugInf:\n",
        "             print(\"CASO 2 - BUG do infinto confirmado [\", dicTableGT[\"TABLEID\"], \"] posInf \", posInf)\n",
        "             dicTable[\"TABLEID\"] = dicTableGT[\"TABLEID\"]\n",
        "             dicTable[\"DIMENSION\"] = dicTableGT[\"DIMENSION\"]\n",
        "             dicTable[\"HEAD\"].insert(posInf, \"NAN\")\n",
        "             dicTable[\"FIRST_LINE\"].insert(posInf, char)\n",
        "             dicTable[\"OBS\"] = \"CASO 2 - TABELAS SIMILARES (BUG INFINITO)\"\n",
        "             #print(\"CASO 2 - Comparacao, dicTable depois: \", dicTable)\n",
        "             isBugInfinito = True\n",
        "             #remove da lista de dicionario o valor do tableid encontrado\n",
        "             listTablesInfoGT[:] = [dic for dic in listTablesInfoGT if dic.get(\"TABLEID\") != dicTable[\"TABLEID\"]]\n",
        "             break\n",
        "\n",
        "      #CASO 3 - Coletar maior similaridade entre as tabelas da mesma página (de mesma dimensao)\n",
        "      if not equalTables and not isBugInfinito:\n",
        "        print(\"CASO 3 - Coletar maior similaridade entre as tabelas da mesma página\")\n",
        "        dicTable[\"TABLEID\"] = getMaiorSimilaridade(dicTable, listTablesInfoGT)\n",
        "        listFileGT = getGTInfo(dicTable[\"TABLEID\"], noExtension, page, GT_LAB_OUT)\n",
        "        listTableInfoGT = getListTablesInfo(GT_LAB_OUT,listFileGT)\n",
        "        if(len(listTableInfoGT) > 0):\n",
        "          print(\"entrou getListTablesInfo \", listTableInfoGT[0][\"DIMENSION\"])\n",
        "          dicTable[\"DIMENSION\"] = listTableInfoGT[0][\"DIMENSION\"]\n",
        "        dicTable[\"OBS\"] = \"CASO 3 - TABELA DE MAIOR SIMILARIDADE\"\n",
        "        print(\"TABLEID de maior similaridade = \", dicTable[\"TABLEID\"])\n",
        "        #remove da lista de dicionario o valor do tableid encontrado\n",
        "        listTablesInfoGT[:] = [dic for dic in listTablesInfoGT if dic.get(\"TABLEID\") != dicTable[\"TABLEID\"]]\n",
        "\n",
        "      print(\"dicTable HEAD\", dicTable[\"HEAD\"])\n",
        "      print(\"dicTable FIRST_LINE\", dicTable[\"FIRST_LINE\"])\n",
        "\n",
        "      if dicTable[\"DIMENSION\"] != 0:\n",
        "        qtdLinhasGT = int(dicTable[\"DIMENSION\"].split(\"X\")[0])\n",
        "        qtdColunasGT = int(dicTable[\"DIMENSION\"].split(\"X\")[1])\n",
        "        print(\"Dimensão dicTableGT {0} x {1} \".format(qtdLinhasGT, qtdColunasGT))\n",
        "\n",
        "      #gravar o arquivo INFO da tabela para comparacao com GT\n",
        "      #encontrou tabela identica ou similar\n",
        "      if dicTable[\"TABLEID\"] != \"TBD\" and dicTable[\"TABLEID\"] != \"\":\n",
        "        filePath = labDirOut + dicTable[\"TABLEID\"] + \"|\" + noExtension + \"|\" + str(page) + \"_INFO.info\"\n",
        "        print(\"gerando arquivo INFO de resultado - SUCESSO: \", filePath)\n",
        "        SaveDicTableInfo(filePath, dicTable)\n",
        "      else:\n",
        "        #no caso de nao ter encontrado tabela similar ao GT para comparação, registrar arquivo de erro\n",
        "        filePath = labDirOut + noExtension + \"|\" + str(page) + \"|\" + \"_INFO_ERRO.error\"\n",
        "        dicTable[\"OBS\"] = \"ERRO - TABLEID NÃO ENCONTRADO\"\n",
        "        print(\"gerando arquivo INFO de resultado - ERRO: \", filePath)\n",
        "        SaveDicTableInfo(filePath, dicTable)\n",
        "\n",
        "      #==== 5 - GRAVANDO AS INFORMAÇÕES DAS TABELAS (METADADOS, BBOX E HTML) ======\n",
        "\n",
        "      #encontrou o table ID para comparar com o GT\n",
        "      if dicTable[\"TABLEID\"] != \"TBD\" and dicTable[\"TABLEID\"] != \"\":\n",
        "\n",
        "        #AJUSTANDO ARRAYS (SE NECESSÁRIO) lsData e cell_coordinates\n",
        "        if qtdLinhasData != qtdLinhasGT or qtdColunasData != qtdColunasGT: #corrigir lsData\n",
        "          print(\"Ajustando lstData  - qtdLinhasData =\", qtdLinhasData, \" x qtdLinhasGT =\", qtdLinhasGT)\n",
        "          print(\"Ajustando lstData  - qtdColunasData =\", qtdColunasData, \" x qtdColunasGT =\", qtdColunasGT)\n",
        "          lstData = ajustList(lstData, qtdLinhasGT, qtdColunasGT)\n",
        "\n",
        "        if qtdlinhas != qtdLinhasGT or qtdcolunas != qtdColunasGT: #corrigir cell_coordinates\n",
        "          print(\"Ajustando cell_coordinates  - qtdlinhas =\", qtdlinhas, \" x qtdLinhasGT =\", qtdLinhasGT)\n",
        "          print(\"Ajustando cell_coordinates  - qtdcolunas =\", qtdcolunas, \" x qtdColunasGT =\", qtdColunasGT)\n",
        "          cell_coordinates = ajustCellCord(cell_coordinates, qtdLinhasGT, qtdColunasGT)\n",
        "\n",
        "        #print(\"TABLEID válido, iniciando a coleta de dados (METADADOS E BBOX)...., TABLEID [\",dicTable[\"TABLEID\"],\"]\")\n",
        "        #modelo do dicmetada\n",
        "        dicMetaData = {\n",
        "        \"filename\": 0,\n",
        "        \"split\": \"train\",\n",
        "        \"imgid\": \"\",\n",
        "        \"html\": {\n",
        "          \"cells\": 0,\n",
        "          \"structure\": 0\n",
        "                }\n",
        "        }\n",
        "\n",
        "        #inicializando a lista\n",
        "        dicMetaData[\"filename\"] = path_pdf_in\n",
        "        dicMetaData[\"imgid\"] = dicTable[\"TABLEID\"]\n",
        "\n",
        "        qtdRowBbox = 0\n",
        "        qtdColBbox = 0\n",
        "        #dimensão do BBOX\n",
        "        if cell_coordinates is not None and len(cell_coordinates) > 0:\n",
        "          qtdRowBbox = len(cell_coordinates)\n",
        "          qtdColBbox = len(cell_coordinates[0][\"cells\"])\n",
        "\n",
        "        #dimensao dos dados\n",
        "        qtdRowData = 0\n",
        "        qtdColData = 0\n",
        "        if lstData is not None and len(lstData) > 0:\n",
        "          qtdRowData = len(lstData)\n",
        "          qtdColData = len(lstData[0])\n",
        "\n",
        "        print(\"TABLEID diferente de vazio (APOS TRATAMENTO DAS ESTRUTURAS)...\")\n",
        "        print(\"qtdRowBbox\", qtdRowBbox, \" x qtdColBbox\", qtdColBbox)\n",
        "        print(\"qtdRowData\", qtdRowBbox, \" x qtdColData\", qtdColData)\n",
        "\n",
        "        #se a dimensão do tokens da celula e do BBOX forem identicos, gravar no arquivo\n",
        "        if (qtdRowBbox == qtdRowData and qtdColBbox == qtdColData):\n",
        "\n",
        "          lstCells = []\n",
        "          lstStructure = []\n",
        "\n",
        "          #carrega e concatena a lista de tokens das celulas e bbox calculando como referencia as coordenadas da tabela principal\n",
        "          lstCells.extend(noteListTokensBbox(cell_coordinates, lstData, None))\n",
        "          dfDados = pd.DataFrame(lstData[0:])\n",
        "          lstStructure.extend(noteTokensHTML(dfDados)) #carrega e concatena a lista de tokens html\n",
        "          dicMetaData[\"html\"][\"cells\"] = lstCells\n",
        "          dicMetaData[\"html\"][\"structure\"] = lstStructure\n",
        "\n",
        "          print(\"Gravando Metadados: \", DIROUT_PUBTABLES)\n",
        "          saveAnnotationFile(dicMetaData, DIROUT_PUBTABLES , page)\n",
        "          saveElementMetadata(dicMetaData, \"BBOX\", DIROUT_PUBTABLES, page)\n",
        "          saveElementMetadata(dicMetaData, \"HTML\", DIROUT_PUBTABLES, page)\n",
        "          saveElementMetadata(dicMetaData, \"HTML_PRETTY\", DIROUT_PUBTABLES, page)\n",
        "          deleteFiles(labDirOut, \"png\")\n",
        "        else:\n",
        "          print(\"Dimensão diferente entre as tabelas\")\n",
        "\n",
        "    #break #para cada pagina\n",
        "\n",
        "  #break # para cada arquivo\n",
        "\n",
        "# Obter a data e hora corrente\n",
        "data_e_hora_corrente = datetime.now(fuso_horario_brasilia)\n",
        "# Formatar a data e hora corrente para o formato desejado\n",
        "data_e_hora_formatadas = data_e_hora_corrente.strftime(\"%d/%m/%Y %H:%M:%S\")\n",
        "#MAXFILES = 1 #apenas para testes, delimitar a quantidade de certificados a ler\n",
        "print('FIM DO PROCESSAMENTO ', data_e_hora_formatadas)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QzZrtw9SlgzB"
      },
      "source": [
        "# TEDS - CALCULO PARA O MODELO"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LCNSbPwkl8uc"
      },
      "outputs": [],
      "source": [
        "from IPython.display import clear_output\n",
        "!pip install distance\n",
        "!pip install apted\n",
        "!pip install lxml\n",
        "!pip install tqdm\n",
        "clear_output()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "Xg3pjfOGlgiV",
        "outputId": "e2cbd7db-e319-4945-c66a-ee830656ab91"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\nif __name__ == '__main__':\\n    import json\\n    import pprint\\n    with open('sample_pred.json') as fp:\\n        pred_json = json.load(fp)\\n    with open('sample_gt.json') as fp:\\n        true_json = json.load(fp)\\n    teds = TEDS(n_jobs=4)\\n    scores = teds.batch_evaluate(pred_json, true_json)\\n    pp = pprint.PrettyPrinter()\\n    pp.pprint(scores)\\n \""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 37
        }
      ],
      "source": [
        "import distance\n",
        "from apted import APTED, Config\n",
        "from apted.helpers import Tree\n",
        "from lxml import etree, html\n",
        "from collections import deque\n",
        "#from parallel import parallel_process\n",
        "from tqdm import tqdm\n",
        "\n",
        "class TableTree(Tree):\n",
        "    def __init__(self, tag, colspan=None, rowspan=None, content=None, *children):\n",
        "        self.tag = tag\n",
        "        self.colspan = colspan\n",
        "        self.rowspan = rowspan\n",
        "        self.content = content\n",
        "        self.children = list(children)\n",
        "\n",
        "    def bracket(self):\n",
        "        \"\"\"Show tree using brackets notation\"\"\"\n",
        "        if self.tag == 'td':\n",
        "            result = '\"tag\": %s, \"colspan\": %d, \"rowspan\": %d, \"text\": %s' % \\\n",
        "                     (self.tag, self.colspan, self.rowspan, self.content)\n",
        "        else:\n",
        "            result = '\"tag\": %s' % self.tag\n",
        "        for child in self.children:\n",
        "            result += child.bracket()\n",
        "        return \"{{{}}}\".format(result)\n",
        "\n",
        "\n",
        "class CustomConfig(Config):\n",
        "    @staticmethod\n",
        "    def maximum(*sequences):\n",
        "        \"\"\"Get maximum possible value\n",
        "        \"\"\"\n",
        "        return max(map(len, sequences))\n",
        "\n",
        "    def normalized_distance(self, *sequences):\n",
        "        \"\"\"Get distance from 0 to 1\n",
        "        \"\"\"\n",
        "        return float(distance.levenshtein(*sequences)) / self.maximum(*sequences)\n",
        "\n",
        "    def rename(self, node1, node2):\n",
        "        \"\"\"Compares attributes of trees\"\"\"\n",
        "        if (node1.tag != node2.tag) or (node1.colspan != node2.colspan) or (node1.rowspan != node2.rowspan):\n",
        "            return 1.\n",
        "        if node1.tag == 'td':\n",
        "            if node1.content or node2.content:\n",
        "                return self.normalized_distance(node1.content, node2.content)\n",
        "        return 0.\n",
        "\n",
        "\n",
        "class TEDS(object):\n",
        "    ''' Tree Edit Distance basead Similarity\n",
        "    '''\n",
        "    def __init__(self, structure_only=False, n_jobs=1, ignore_nodes=None):\n",
        "        assert isinstance(n_jobs, int) and (n_jobs >= 1), 'n_jobs must be an integer greather than 1'\n",
        "        self.structure_only = structure_only\n",
        "        self.n_jobs = n_jobs\n",
        "        self.ignore_nodes = ignore_nodes\n",
        "        self.__tokens__ = []\n",
        "\n",
        "    def tokenize(self, node):\n",
        "        ''' Tokenizes table cells\n",
        "        '''\n",
        "        self.__tokens__.append('<%s>' % node.tag)\n",
        "        if node.text is not None:\n",
        "            self.__tokens__ += list(node.text)\n",
        "        for n in node.getchildren():\n",
        "            self.tokenize(n)\n",
        "        if node.tag != 'unk':\n",
        "            self.__tokens__.append('</%s>' % node.tag)\n",
        "        if node.tag != 'td' and node.tail is not None:\n",
        "            self.__tokens__ += list(node.tail)\n",
        "\n",
        "    def load_html_tree(self, node, parent=None):\n",
        "        ''' Converts HTML tree to the format required by apted\n",
        "        '''\n",
        "        global __tokens__\n",
        "        if node.tag == 'td':\n",
        "            if self.structure_only:\n",
        "                cell = []\n",
        "            else:\n",
        "                self.__tokens__ = []\n",
        "                self.tokenize(node)\n",
        "                cell = self.__tokens__[1:-1].copy()\n",
        "            new_node = TableTree(node.tag,\n",
        "                                 int(node.attrib.get('colspan', '1')),\n",
        "                                 int(node.attrib.get('rowspan', '1')),\n",
        "                                 cell, *deque())\n",
        "        else:\n",
        "            new_node = TableTree(node.tag, None, None, None, *deque())\n",
        "        if parent is not None:\n",
        "            parent.children.append(new_node)\n",
        "        if node.tag != 'td':\n",
        "            for n in node.getchildren():\n",
        "                self.load_html_tree(n, new_node)\n",
        "        if parent is None:\n",
        "            return new_node\n",
        "\n",
        "    def evaluate(self, pred, true):\n",
        "        ''' Computes TEDS score between the prediction and the ground truth of a\n",
        "            given sample\n",
        "        '''\n",
        "        if (not pred) or (not true):\n",
        "            return 0.0\n",
        "        parser = html.HTMLParser(remove_comments=True, encoding='utf-8')\n",
        "        pred = html.fromstring(pred, parser=parser)\n",
        "        true = html.fromstring(true, parser=parser)\n",
        "        if pred.xpath('body/table') and true.xpath('body/table'):\n",
        "            pred = pred.xpath('body/table')[0]\n",
        "            true = true.xpath('body/table')[0]\n",
        "            if self.ignore_nodes:\n",
        "                etree.strip_tags(pred, *self.ignore_nodes)\n",
        "                etree.strip_tags(true, *self.ignore_nodes)\n",
        "            n_nodes_pred = len(pred.xpath(\".//*\"))\n",
        "            n_nodes_true = len(true.xpath(\".//*\"))\n",
        "            n_nodes = max(n_nodes_pred, n_nodes_true)\n",
        "            tree_pred = self.load_html_tree(pred)\n",
        "            tree_true = self.load_html_tree(true)\n",
        "            distance = APTED(tree_pred, tree_true, CustomConfig()).compute_edit_distance()\n",
        "            return 1.0 - (float(distance) / n_nodes)\n",
        "        else:\n",
        "            return 0.0\n",
        "\n",
        "    def batch_evaluate(self, pred_json, true_json):\n",
        "        ''' Computes TEDS score between the prediction and the ground truth of\n",
        "            a batch of samples\n",
        "            @params pred_json: {'FILENAME': 'HTML CODE', ...}\n",
        "            @params true_json: {'FILENAME': {'html': 'HTML CODE'}, ...}\n",
        "            @output: {'FILENAME': 'TEDS SCORE', ...}\n",
        "        '''\n",
        "        samples = true_json.keys()\n",
        "        if self.n_jobs == 1:\n",
        "            scores = [self.evaluate(pred_json.get(filename, ''), true_json[filename]['html']) for filename in tqdm(samples)]\n",
        "        else:\n",
        "            inputs = [{'pred': pred_json.get(filename, ''), 'true': true_json[filename]['html']} for filename in samples]\n",
        "            scores = parallel_process(inputs, self.evaluate, use_kwargs=True, n_jobs=self.n_jobs, front_num=1)\n",
        "        scores = dict(zip(samples, scores))\n",
        "        return scores\n",
        "\n",
        "'''\n",
        "if __name__ == '__main__':\n",
        "    import json\n",
        "    import pprint\n",
        "    with open('sample_pred.json') as fp:\n",
        "        pred_json = json.load(fp)\n",
        "    with open('sample_gt.json') as fp:\n",
        "        true_json = json.load(fp)\n",
        "    teds = TEDS(n_jobs=4)\n",
        "    scores = teds.batch_evaluate(pred_json, true_json)\n",
        "    pp = pprint.PrettyPrinter()\n",
        "    pp.pprint(scores)\n",
        " '''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qz6y7hnIgVzo"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "#FUNCAO DE VERIFICA SE EXISTE O BUG DE TRUNCAR O VALOR ∞\n",
        "\n",
        "def isBUGInfinito(dicTable, dicTableGT):\n",
        "\n",
        "  posInf = getPos(dicTableGT[\"FIRST_LINE\"], \"∞\")\n",
        "\n",
        "  #possui valor ∞ na tabela? segue análise\n",
        "  if posInf >-1:\n",
        "    print(\"Possui valor ∞ na tabela\")\n",
        "    #2 - possuem o mesmo valor de dimensao em DIMENSION\n",
        "    if dicTable[\"DIMENSION\"] == dicTableGT[\"DIMENSION\"]:\n",
        "      print(\"Valor DIMENSION iguais\")\n",
        "      #3 primeiras colunas das duas tabelas possuem o mesmo valor?\n",
        "      if checkAVGSimilarities2INFO(dicTableGT, dicTable, 80):\n",
        "        print(\"Três primeiras colunas similares\")\n",
        "        #4 - chave HEAD tem o tamanho um a menos que GT\n",
        "        if len(dicTable[\"HEAD\"]) == len(dicTableGT[\"HEAD\"])-1 and len(dicTable[\"FIRST_LINE\"]) == len(dicTableGT[\"FIRST_LINE\"])-1:\n",
        "          #dicTable[\"FIRST_LINE\"].insert(posInf, \"∞\")\n",
        "          return True, posInf\n",
        "\n",
        "  return False, -1\n",
        "\n",
        "#funcao para ajustar o valor\n",
        "\n",
        "isBUGInfinito(dicTable, dicTableGT)\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "anqFpPNNoFYg"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "#verificar possivel similaridade no cabeçalho dos dicionários INFO\n",
        "def checkINFOFirstLine(dicTableGT, dicTable, percTolerancia):\n",
        "\n",
        "  qtdColGT = len(dicTableGT[\"FIRST_LINE\"])\n",
        "  qtdColTab = len(dicTable[\"FIRST_LINE\"])\n",
        "\n",
        "  arrSim = []\n",
        "  arrSummary = []\n",
        "  limit = 4\n",
        "\n",
        "  #verificar similaridade nas 3 primeiras colunas\n",
        "  for i in range(qtdColTab):\n",
        "\n",
        "    for j in range(qtdColGT):\n",
        "      strTab = dicTable[\"FIRST_LINE\"][i]\n",
        "      strGT = dicTableGT[\"FIRST_LINE\"][j]\n",
        "      arrSim.append(calcPercSimStrings(strTab, strGT))\n",
        "\n",
        "    arrSummary.append(maiorValor(arrSim))\n",
        "    arrSim = []\n",
        "\n",
        "  #print(arrSummary)\n",
        "  avgPerc = sum(arrSummary) / len(arrSummary)\n",
        "  return avgPerc >= percTolerancia\n",
        "  '''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "76OVF5L2LuhE"
      },
      "source": [
        "# 5 - Função MAIN para gerar estatísticas (ARQUIVOS GT VERSUS IMAGE2TABLE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vNOu2NhiL-Uk"
      },
      "source": [
        "Funcoes basicas para estatisticas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bBoLv_nVjIDl",
        "outputId": "feaea478-9609-4780-b93f-ea29bcfab046"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "#montando o caminho para leitura dos arquivos (certificados, imagens, planilhas, etc)\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rBlCroEiLtlz"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import glob\n",
        "import json\n",
        "\n",
        "#coletar as informacoes da tabela do arquivo _INFO e retornar para uma lista\n",
        "def getListTablesInfo(path, listFiles):\n",
        "\n",
        "  listTablesInfo = []\n",
        "  for fileName in listFiles:\n",
        "    with open(path + fileName, 'r') as file:\n",
        "      conteudo = file.read()\n",
        "      listTablesInfo.append(eval(conteudo))\n",
        "\n",
        "  return listTablesInfo\n",
        "\n",
        "def sortList(lst, len):\n",
        "    def personList(item):\n",
        "        # Extrai o número após 'CTM' e converte para inteiro\n",
        "        return int(item[len:])\n",
        "\n",
        "    return sorted(lst, key=personList)\n",
        "\n",
        "#coletar arquivo de acordo com premissas (prefixo e sufixo)\n",
        "def getFileByPrefix(path, prefix, sufix):\n",
        "\n",
        "  for fileName in os.listdir(path):\n",
        "      if prefix in fileName and fileName.endswith(sufix):\n",
        "          return fileName\n",
        "  return \"\"\n",
        "\n",
        "def getFiles(folderDir, ext):\n",
        "  # Construir o padrão de busca usando a extensão fornecida\n",
        "  pattern = os.path.join(folderDir, f\"*.{ext}\")\n",
        "\n",
        "  files = []\n",
        "  arrPath = folderDir.split(\"/\")\n",
        "\n",
        "  #print(\"arrPath \", arrPath)\n",
        "  if len(arrPath) >0 and len(arrPath[len(arrPath)-1].split(\"_\")) >0:\n",
        "    #print(folderDir)\n",
        "    lab = arrPath[len(arrPath)-1].split(\"_\")[2]\n",
        "    # Usar a função glob para encontrar os arquivos correspondentes ao padrão\n",
        "    files = glob.glob(pattern)\n",
        "\n",
        "  # Retornar a lista de arquivos encontrados\n",
        "  return sorted(files)\n",
        "\n",
        "def getInfoFiles(list):\n",
        "\n",
        "  lstInfoFiles = []\n",
        "  for path in list:\n",
        "\n",
        "    arrPath = path.split(\"/\")\n",
        "    file = arrPath[len(arrPath)-1]\n",
        "    tableId = file.split(\"|\")[0]\n",
        "    fileName = file.split(\"|\")[1]\n",
        "    page = file.split(\"|\")[2].split(\"_\")[0]\n",
        "\n",
        "    lstInfoFiles.append({\"TABLEID\":tableId, \"TABLEID\":tableId, \"FILE\":fileName, \"PAGE\":page})\n",
        "\n",
        "  return lstInfoFiles\n",
        "\n",
        "#funcao que compara o valor de duas listas e calcula a media do percentual de similaridade entre eles\n",
        "#(para calcular o valor do bbox das tabelas e células das tabelas)\n",
        "def calcPercSimValueLists(lista1, lista2):\n",
        "  if len(lista1) != len(lista2):\n",
        "      print(\"calcPercSimValueLists, listas de tamanhos diferentes, lista1=\",lista1,\"/ lista2 = \",lista2)\n",
        "      raise ValueError(\"As listas devem ter o mesmo comprimento.\")\n",
        "\n",
        "  percSim = [ (1 / (1 + (abs(num1 - num2)))) * 100 for num1, num2 in zip(lista1, lista2)]\n",
        "  #print(\"percSim \", percSim)\n",
        "  #print(\"result percSim \", sum(percSim) / len (percSim))\n",
        "  return sum(percSim) / len (percSim)\n",
        "\n",
        "#(para calcular o percentual de similaridade entre dois números\n",
        "def calcPercSimValueNums(num1, num2):\n",
        "\n",
        "  percSim = (1 / (1 + (abs(num1 - num2)))) * 100\n",
        "  #print (\" similaridade entre os numeros {0} e {1}: {2}\".format(num1, num2, percSim))\n",
        "  return percSim\n",
        "\n",
        "#similaridade de strings conhecido como \"Distância de Levenshtein\"\n",
        "def calcPercSimStrings(str1, str2):\n",
        "\n",
        "  #retirando quebra de linhas da string\n",
        "  str1 = str1.replace(\"\\n\", \" \")\n",
        "  str2 = str2.replace(\"\\n\", \" \")\n",
        "\n",
        "  tamanho_str1 = len(str1)\n",
        "  tamanho_str2 = len(str2)\n",
        "\n",
        "  matriz = [[0] * (tamanho_str2 + 1) for _ in range(tamanho_str1 + 1)]\n",
        "\n",
        "  for i in range(tamanho_str1 + 1):\n",
        "    matriz[i][0] = i\n",
        "\n",
        "  for j in range(tamanho_str2 + 1):\n",
        "    matriz[0][j] = j\n",
        "\n",
        "  for i in range(1, tamanho_str1 + 1):\n",
        "    for j in range(1, tamanho_str2 + 1):\n",
        "        if str1[i - 1] == str2[j - 1]:\n",
        "            custo_substituicao = 0\n",
        "        else:\n",
        "            custo_substituicao = 1\n",
        "        matriz[i][j] = min(matriz[i - 1][j] + 1,       # Deletar\n",
        "                            matriz[i][j - 1] + 1,       # Inserir\n",
        "                              matriz[i - 1][j - 1] + custo_substituicao)  # Substituir\n",
        "\n",
        "  distancia = matriz[tamanho_str1][tamanho_str2]\n",
        "  maximo_tamanho = max(tamanho_str1, tamanho_str2)\n",
        "\n",
        "  similaridade = 0\n",
        "  if maximo_tamanho > 0:\n",
        "    similaridade = (maximo_tamanho - distancia) / maximo_tamanho\n",
        "  #print (\" similaridade entre {0} e {1}: {2}\".format(str1, str2, similaridade * 100))\n",
        "  return similaridade * 100\n",
        "\n",
        "#numero de ocorrencias de um numero em uma lista\n",
        "def numTimes(list, num):\n",
        "\n",
        "  cont = 0\n",
        "  for valor in list:\n",
        "    if valor == num:\n",
        "      cont+=1\n",
        "\n",
        "  return cont\n",
        "\n",
        "#numero de ocorrencias de um numero ser maior ou igual que um numero\n",
        "def numTimesMoreThen(list, num):\n",
        "\n",
        "  cont = 0\n",
        "  for valor in list:\n",
        "    if valor >= num and valor <100:\n",
        "      cont+=1\n",
        "\n",
        "  return cont\n",
        "\n",
        "def isDecimal(valor):\n",
        "  try:\n",
        "      float(valor)\n",
        "      return True\n",
        "  except ValueError:\n",
        "      return False\n",
        "\n",
        "#calcular similaridades em valores das celulas bbox e tokens de duas listas de tabelas\n",
        "def calStatsTablesValues(lstTable1, lstTable2):\n",
        "\n",
        "  lstResTokens = []\n",
        "  lstResBbox = []\n",
        "  for item1, item2 in zip(lstTable1, lstTable2):\n",
        "    listaBbox1 = item1[\"bbox\"]\n",
        "    listaBbox2 = item2[\"bbox\"]\n",
        "    str1 = \"\".join(item1[\"tokens\"])\n",
        "    str2 = \"\".join(item2[\"tokens\"])\n",
        "\n",
        "    if len(listaBbox1) >0 and len(listaBbox2) >0:\n",
        "      lstResBbox.append(round(calcPercSimValueLists(listaBbox1, listaBbox2),2))\n",
        "    else:\n",
        "      lstResBbox.append(0)\n",
        "\n",
        "    strDec1 = str1.replace(\",\", \".\").strip()\n",
        "    strDec2 = str2.replace(\",\", \".\").strip()\n",
        "    #se os valores forem numeros converter para float para calcular similiaridade com maior exatidao\n",
        "    if (isDecimal(strDec1) and isDecimal(strDec2)):\n",
        "      lstResTokens.append( round( calcPercSimValueNums(float(strDec1), float(strDec2) ),2) )\n",
        "    #no caso de string\n",
        "    else:\n",
        "      lstResTokens.append(round(calcPercSimStrings(str1, str2),2))\n",
        "\n",
        "  return lstResTokens, lstResBbox\n",
        "\n",
        "#calcular quantidade de valores não lidos pelo modelo (NAN ou 999999)\n",
        "def calStatsNAN(lstTable):\n",
        "\n",
        "  qtdNANToken = 0\n",
        "  qtdNANBbox = 0\n",
        "\n",
        "  for item in lstTable:\n",
        "    listaBbox = item[\"bbox\"]\n",
        "    token = \"\".join(item[\"tokens\"])\n",
        "\n",
        "    if numTimes(listaBbox, 999999) ==4:\n",
        "      qtdNANBbox+=1\n",
        "\n",
        "    if token == \"NAN\":\n",
        "      qtdNANToken+=1\n",
        "\n",
        "  return qtdNANToken, qtdNANBbox\n",
        "\n",
        "def readFile(filePath):\n",
        "  try:\n",
        "    with open(filePath, 'r') as arquivo:\n",
        "        conteudo = arquivo.read()\n",
        "    return conteudo\n",
        "  except FileNotFoundError:\n",
        "    print(f'O arquivo \"{filePath}\" não foi encontrado.')\n",
        "    return None\n",
        "  except Exception as e:\n",
        "    print(f'Ocorreu um erro ao ler o arquivo: {e}')\n",
        "    return None\n",
        "\n",
        "def SaveFileStats (filePath, dicTableStats):\n",
        "\n",
        "  strFile = json.dumps(dicTableStats)\n",
        "  strFile = strFile.replace(\",\",\",\\n\")\n",
        "\n",
        "  print(\"Salvando arquivo de estatísticas: \",filePath)\n",
        "  with open(filePath, 'w') as arquivo:\n",
        "    arquivo.write(strFile)\n",
        "\n",
        "def strInDic(dicionario, string):\n",
        "\n",
        "  for chave, valor in dicionario.items():\n",
        "      if isinstance(valor, str) and string in valor:\n",
        "          return True\n",
        "  return False\n",
        "\n",
        "def strInList(lstDic, string):\n",
        "\n",
        "  for dic in lstDic:\n",
        "    for chave, valor in dic.items():\n",
        "        if isinstance(valor, str) and string == valor:\n",
        "            return True\n",
        "  return False\n",
        "\n",
        "def ExportCSVSummary(ToolPath, GTPath):\n",
        "  #coletando os diretorios dos laboratorios\n",
        "  dirLabs = [nome for nome in os.listdir(ToolPath)]\n",
        "\n",
        "  listStats = []\n",
        "  filesSTATS = []\n",
        "\n",
        "  lstTableIdGT = []\n",
        "  #colentando os arquivos de statisticas dos laboratorios\n",
        "  for dirLab in dirLabs:\n",
        "\n",
        "    labPath =  ToolPath + dirLab\n",
        "    filesSTATS = getFiles(labPath, \"stats\")\n",
        "\n",
        "    #print(\"filesSTATS \", filesSTATS)\n",
        "    #coletando arquivos de estatisticas\n",
        "    for fileSTATS in filesSTATS:\n",
        "      dicStats = ast.literal_eval(readFile(fileSTATS))\n",
        "      listStats.append(dicStats)\n",
        "\n",
        "    #coletando os tablesID do GT para comparacao\n",
        "    filesGTInfo = GTPath + dirLab\n",
        "    filesInfo = getFiles(filesGTInfo, \"info\")\n",
        "\n",
        "    #print(\"filesInfo \", filesInfo)\n",
        "\n",
        "    for fileInfo in filesInfo:\n",
        "      arrFile = fileInfo.split(\"/\")\n",
        "      tableId = arrFile[len(arrFile)-1].split(\"|\")[0]\n",
        "      lstTableIdGT.append(dirLab+\"|\"+tableId)\n",
        "\n",
        "  lstErros = []\n",
        "\n",
        "  for item in lstTableIdGT:\n",
        "\n",
        "    #print(item)\n",
        "    lab = item.split(\"|\")[0]\n",
        "    tableId = item.split(\"|\")[1]\n",
        "    if not strInList(listStats, tableId): #não encontrou, adicionar ao erro\n",
        "\n",
        "      print(\"Não encontrou TABLEID \", tableId, \", adicionando....\")\n",
        "      #print(\"GTPath \", GTPath)\n",
        "      #print(\"lab \", lab)\n",
        "      #print(\"tableId \", tableId)\n",
        "      print(\"fileInfo \", fileInfo)\n",
        "\n",
        "      #coletando informacoes do statsInfo\n",
        "      #print(\"parametros a carregar na funcao getFileByPrefix\", GTPath + lab, tableId+\"|\", \"info\")\n",
        "      fileInfo = getFileByPrefix(GTPath + lab, tableId+\"|\", \"info\")\n",
        "      #pathInfo = GTPath + dirLab + fileInfo\n",
        "      lstFile = [fileInfo]\n",
        "      #print(\"parametros a carregar na funcao getListTablesInfo\", GTPath + lab + \"/\", lstFile)\n",
        "      lstInfo = getListTablesInfo(GTPath + lab + \"/\", lstFile)\n",
        "\n",
        "      dicTableStats = {}\n",
        "      dicTableStats[\"LAB\"] = lstInfo[0][\"LAB\"]\n",
        "      dicTableStats[\"FILE\"] = lstInfo[0][\"FILE\"]\n",
        "      dicTableStats[\"PAGE\"] = lstInfo[0][\"PAGE\"]\n",
        "      dicTableStats[\"TABLEID\"] = lstInfo[0][\"TABLEID\"]\n",
        "      dicTableStats[\"DIMENSION\"] = lstInfo[0][\"DIMENSION\"]\n",
        "      dicTableStats[\"QTDCELLS\"] = 0\n",
        "      dicTableStats[\"QTDACERTOSCELLS\"] = 0\n",
        "      dicTableStats[\"PERCACERTOSCELLS\"] = 0\n",
        "      dicTableStats[\"PERCACERTOSBBOX\"] = 0\n",
        "      dicTableStats[\"QTDNAOLIDOSBBOX\"] = 0\n",
        "      dicTableStats[\"PERCNAOLIDOSBBOX\"] = 0\n",
        "      dicTableStats[\"QTDNAOLIDOSTOKEN\"] = 0\n",
        "      dicTableStats[\"PERCNAOLIDOSTOKEN\"] = 0\n",
        "      dicTableStats[\"TEDS\"] = 0\n",
        "\n",
        "      lstErros.append(dicTableStats)\n",
        "\n",
        "  lstTotal = listStats + lstErros\n",
        "\n",
        "  dtStats = pd.DataFrame(lstTotal)\n",
        "  dtStatsORD = dtStats.sort_values(by=['LAB','FILE', 'PAGE'])\n",
        "  #print(dtStatsORD)\n",
        "  print(\"Arquivo de sumário gerado \", ToolPath + \"Summary.xlsx\")\n",
        "  dtStatsORD.to_excel(ToolPath + \"Summary.xlsx\", index=False)  # index=False para não incluir o índice do DataFrame\n",
        "  return dtStatsORD"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o3N1-Z3XMCyo"
      },
      "outputs": [],
      "source": [
        "#gerando estatísticas\n",
        "\n",
        "import os\n",
        "import ast\n",
        "import pandas as pd\n",
        "\n",
        "#diretorio do img2tableDir\n",
        "pubTables = \"/content/drive/MyDrive/DataSets/Certificados/Out/PubTables/\"\n",
        "#diretorio de referencia GT\n",
        "GTDir = \"/content/drive/MyDrive/DataSets/Certificados/Out/GT/\"\n",
        "\n",
        "#coletando os diretorios dos laboratorios\n",
        "#dirLabs = [nome for nome in os.listdir(pubTables)]\n",
        "\n",
        "dirLabs = [] #INFORMAR A LISTA DE PASTAS DE ARQUIVOS POR LABORATÓRIO AQUI\n",
        "\n",
        "for dirLab in dirLabs:\n",
        "\n",
        "  if not os.path.isfile(dirLab):\n",
        "    labPath =  pubTables + dirLab\n",
        "    labPathGT =  GTDir + dirLab\n",
        "    #coleta os arquivos info para analise dos tablesID\n",
        "    filesINFO = getFiles(labPath, \"info\")\n",
        "    #coleta os tablesID para comparacao\n",
        "    lstInfoFiles = getInfoFiles(filesINFO)\n",
        "\n",
        "    #para cada tableID, gerar estatísticas\n",
        "    for dicInfoFile in lstInfoFiles:\n",
        "\n",
        "      print(\"dicInfoFile\", dicInfoFile)\n",
        "      fileInfo = dicInfoFile[\"TABLEID\"] + \"|\" + dicInfoFile[\"FILE\"] + \"|\" + dicInfoFile[\"PAGE\"] + \"_INFO.info\"\n",
        "      fileTokenBbox = dicInfoFile[\"TABLEID\"] + \"|\" + dicInfoFile[\"FILE\"] + \"|\" + dicInfoFile[\"PAGE\"] + \"_BBOX.bbox\"\n",
        "      fileHTML = dicInfoFile[\"TABLEID\"] + \"|\" + dicInfoFile[\"FILE\"] + \"|\" + dicInfoFile[\"PAGE\"] + \"_HTML.html\"\n",
        "\n",
        "      pathFileInfo = labPath + \"/\" + fileInfo\n",
        "      pathFileTokenBbox = labPath + \"/\" + fileTokenBbox\n",
        "      pathFileHTML = labPath + \"/\" + fileHTML\n",
        "\n",
        "      pathFileInfoGT = labPathGT + \"/\" + fileInfo\n",
        "      pathFileTokenBboxGT = labPathGT + \"/\" + fileTokenBbox\n",
        "      pathFileHTMLGT = labPathGT + \"/\" + fileHTML\n",
        "      print(\"pathFileInfo =\", pathFileInfo)\n",
        "\n",
        "      #gerando estatisticas do token e bbox\n",
        "      if os.path.exists(pathFileHTMLGT) and os.path.exists(pathFileTokenBbox) and os.path.exists(pathFileTokenBboxGT):\n",
        "\n",
        "        #carrega lista de tokens/bbox e HTMLs para comparacao do arquivo corrente com GT\n",
        "        #arquivo info GT (.info)\n",
        "        lstInfo = ast.literal_eval(readFile(pathFileInfoGT))\n",
        "        #arquivo bbox (.bbox)\n",
        "        lstTkBox = ast.literal_eval(readFile(pathFileTokenBbox))\n",
        "        #arquivo bbox GT (.bbox)\n",
        "\n",
        "        lstTkBoxGT = ast.literal_eval(readFile(pathFileTokenBboxGT))\n",
        "        #arquivo html (.html)\n",
        "        strHTML = \"\".join(ast.literal_eval(readFile(pathFileHTML).replace(\"\\n\", \" \")))\n",
        "        #arquivo html GT(.html)\n",
        "        strHTMLGT = \"\".join(ast.literal_eval(readFile(pathFileHTMLGT).replace(\"\\n\", \" \")))\n",
        "        #break\n",
        "\n",
        "        #TEDS apenas funciona se tiver na estrutura html as tags html e body\n",
        "        if \"<body>\" not in strHTML:\n",
        "          strHTML = \"<body>\" + strHTML + \"</body>\"\n",
        "        if \"<html>\" not in strHTML:\n",
        "          strHTML = \"<html>\" + strHTML + \"</html>\"\n",
        "        if \"<body>\" not in strHTMLGT:\n",
        "          strHTMLGT = \"<body>\" + strHTMLGT + \"</body>\"\n",
        "        if \"<html>\" not in strHTMLGT:\n",
        "          strHTMLGT = \"<html>\" + strHTMLGT + \"</html>\"\n",
        "\n",
        "        qtdLinhas = int(lstInfo[\"DIMENSION\"].split(\"X\")[0])\n",
        "        qtdColunas = int(lstInfo[\"DIMENSION\"].split(\"X\")[1])\n",
        "        qtdCells = qtdLinhas * qtdColunas\n",
        "\n",
        "        #print(\"lstTkBox\",lstTkBox)\n",
        "        #print(\"lstTkBoxGT\",lstTkBoxGT)\n",
        "        lstStatsTokens, lstStatsBbox = calStatsTablesValues(lstTkBox, lstTkBoxGT)\n",
        "\n",
        "        qtdNANToken, qtdNANBbox = calStatsNAN(lstTkBox)\n",
        "\n",
        "        #calcula qtd de acertos (com similaridade 100% entre os valores dos tokens e tabelas)\n",
        "        qtdAcertosTokens = numTimes(lstStatsTokens, 100.0)\n",
        "        #qtdAcertosBbox = numTimes(lstStatsBbox, 100.0)\n",
        "        percAcertosBbox = round((sum(lstStatsBbox) / len(lstStatsBbox))/100, 2)\n",
        "\n",
        "        #calcula similidade maior que 95%\n",
        "        qtdTokensMaior95 = numTimesMoreThen(lstStatsTokens, 95)\n",
        "        qtdBboxMaior95 = numTimesMoreThen(lstStatsBbox, 95)\n",
        "\n",
        "        #calcula TEDS entre as estruturas HTMLs (img2table VS GT)\n",
        "        teds = TEDS()\n",
        "\n",
        "        scoreTEDS = round(teds.evaluate(strHTML, strHTMLGT), 6)\n",
        "\n",
        "        #salvado arquivo de estatística\n",
        "        fileStats = dicInfoFile[\"TABLEID\"] + \"|\" + dicInfoFile[\"FILE\"] + \"|\" + dicInfoFile[\"PAGE\"] + \"_STATS.stats\"\n",
        "        pathFileStats = labPath + \"/\" + fileStats\n",
        "\n",
        "        percAcertosTokens = round((qtdAcertosTokens / qtdCells), 2)\n",
        "        percNaoLidosBbox = round((qtdNANBbox / qtdCells), 2)\n",
        "        percNaoLidosToken = round((qtdNANToken / qtdCells), 2)\n",
        "\n",
        "        dicTableStats = {}\n",
        "        dicTableStats[\"LAB\"] = lstInfo[\"LAB\"]\n",
        "        dicTableStats[\"FILE\"] = dicInfoFile[\"FILE\"]\n",
        "        dicTableStats[\"PAGE\"] = dicInfoFile[\"PAGE\"]\n",
        "        dicTableStats[\"TABLEID\"] = dicInfoFile[\"TABLEID\"]\n",
        "        dicTableStats[\"DIMENSION\"] = lstInfo[\"DIMENSION\"]\n",
        "        dicTableStats[\"QTDCELLS\"] = qtdCells\n",
        "        dicTableStats[\"QTDACERTOSCELLS\"] = qtdAcertosTokens\n",
        "        dicTableStats[\"PERCACERTOSCELLS\"] = percAcertosTokens\n",
        "        dicTableStats[\"PERCACERTOSBBOX\"] = percAcertosBbox\n",
        "        dicTableStats[\"QTDNAOLIDOSBBOX\"] = qtdNANBbox\n",
        "        dicTableStats[\"PERCNAOLIDOSBBOX\"] = percNaoLidosBbox\n",
        "        dicTableStats[\"QTDNAOLIDOSTOKEN\"] = qtdNANToken\n",
        "        dicTableStats[\"PERCNAOLIDOSTOKEN\"] = percNaoLidosToken\n",
        "        #dicTableStats[\"QTDCELLSMAIOR95\"] = qtdTokensMaior95\n",
        "        #dicTableStats[\"QTDABBOXMAIOR95\"] = qtdBboxMaior95\n",
        "        dicTableStats[\"TEDS\"] = scoreTEDS\n",
        "\n",
        "        SaveFileStats (pathFileStats, dicTableStats)\n",
        "\n",
        "        print(\"Dimensão da tabela \", lstInfo[\"DIMENSION\"], \", total \", str(qtdCells), \" células\" )\n",
        "        print(\"qtdCells:\",qtdCells)\n",
        "        print(\"qtdAcertosTokens:\",qtdAcertosTokens)\n",
        "        print(\"percAcertosTokens:\",percAcertosTokens,\"/\",(percAcertosTokens*100),\"%\")\n",
        "        print(\"percAcertosBbox:\",percAcertosBbox,\"/\",(percAcertosBbox*100),\"%\")\n",
        "        print(\"qtdNaoLidosBbox:\",qtdNANBbox)\n",
        "        print(\"percNaoLidosBbox:\",percNaoLidosBbox,\"/\",(percNaoLidosBbox*100),\"%\")\n",
        "        print(\"qtdNaoLidosTokens:\",qtdNANToken)\n",
        "        print(\"percNaoLidosToken:\",percNaoLidosToken,\"/\",(percNaoLidosToken*100),\"%\")\n",
        "        #print(\"qtdAcertosTokens>95:\",qtdTokensMaior95)\n",
        "        #print(\"qtdAcertosBbox>95:\",qtdBboxMaior95)\n",
        "        print('TEDS score:', scoreTEDS,\"/\",round((scoreTEDS*100),2),\"%\")\n",
        "        #break # fim primeiro for\n",
        "\n",
        "#depois de gerar arquivos de estatística, montar sumário no EXCEL\n",
        "ExportCSVSummary(pubTables, GTDir)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "QCgfALxjC09U",
        "aMtTqGEXC2zj",
        "hEc2twKdE35L",
        "tDiKix_JFgUj",
        "6f_IcaDtFyYg",
        "9iFdr8OVgOIG",
        "Hcx3G0SOgP9x",
        "eObbPVUHnPTj",
        "WeUk901W7yT9",
        "X6WbJHsK6xHw",
        "as36T2-zIrJh",
        "vy91l_PNJ5IR",
        "QzZrtw9SlgzB"
      ],
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}